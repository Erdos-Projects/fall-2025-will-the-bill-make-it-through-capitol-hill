{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c8a863a",
   "metadata": {},
   "source": [
    "# Will the bill make it through capitol hill? (Bills Text Sample Data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc5c84b",
   "metadata": {},
   "source": [
    "## Critical issues in this notebook: \n",
    "\n",
    "**Problem 1: Label leakage**\n",
    "\n",
    "The text after cleaning still includes post-approval metadata that directly reveals the outcome.\n",
    "\n",
    "Leakage sources look like:\n",
    "\n",
    "* “Public Law ###”\n",
    "\n",
    "* “Approved January …”\n",
    "\n",
    "* “considered and passed …”\n",
    "\n",
    "These must be taken care accordingly.\n",
    "\n",
    "**Problem 2: Validation instability**\n",
    "\n",
    "We tune thresholds on 6 positive samples (validation set). That is nowhere near enough for:\n",
    "\n",
    "* Threshold optimization\n",
    "\n",
    "* Reliable F1 calibration\n",
    "\n",
    "* Metrics fluctuate wildly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0cc4eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re # Import re for regular expressions\n",
    "from bs4 import BeautifulSoup\n",
    "# from sentence_transformers import SentenceTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from scipy.sparse import hstack\n",
    "from scipy.sparse import csr_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c333739",
   "metadata": {},
   "source": [
    "# 1a. Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d51159a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the working directory\n",
    "p = r\"C:/Users/saram/Desktop/Erdos_Institute/project-2025/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42c9bde1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13812, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>law</th>\n",
       "      <th>full_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>118.HR.9124</td>\n",
       "      <td>2024-07-24 00:00:00</td>\n",
       "      <td>True</td>\n",
       "      <td>&lt;html&gt;&lt;body&gt;&lt;pre&gt;\\n[118th Congress Public Law ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>118.HR.8667</td>\n",
       "      <td>2024-06-07 00:00:00</td>\n",
       "      <td>True</td>\n",
       "      <td>&lt;html&gt;&lt;body&gt;&lt;pre&gt;\\n[118th Congress Public Law ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>119.HJRES.9</td>\n",
       "      <td>2025-01-03 00:00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>&lt;html&gt;&lt;body&gt;&lt;pre&gt;\\n[Congressional Bills 119th ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>119.HJRES.8</td>\n",
       "      <td>2025-01-03 00:00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>&lt;html&gt;&lt;body&gt;&lt;pre&gt;\\n[Congressional Bills 119th ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>119.HJRES.2</td>\n",
       "      <td>2025-01-03 00:00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>&lt;html&gt;&lt;body&gt;&lt;pre&gt;\\n[Congressional Bills 119th ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13807</th>\n",
       "      <td>113.HJRES.54</td>\n",
       "      <td>2013-07-24 00:00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>&lt;html&gt;&lt;body&gt;&lt;pre&gt;\\n[Congressional Bills 113th ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13808</th>\n",
       "      <td>113.HJRES.53</td>\n",
       "      <td>2013-07-24 00:00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>&lt;html&gt;&lt;body&gt;&lt;pre&gt;\\n[Congressional Bills 113th ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13809</th>\n",
       "      <td>113.HJRES.52</td>\n",
       "      <td>2013-07-24 00:00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>&lt;html&gt;&lt;body&gt;&lt;pre&gt;\\n[Congressional Bills 113th ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13810</th>\n",
       "      <td>113.S.1504</td>\n",
       "      <td>2013-09-12 00:00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>&lt;html&gt;&lt;body&gt;&lt;pre&gt;\\n[Congressional Bills 113th ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13811</th>\n",
       "      <td>113.HJRES.61</td>\n",
       "      <td>2013-09-11 00:00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>&lt;html&gt;&lt;body&gt;&lt;pre&gt;\\n[Congressional Bills 113th ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13812 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                 date    law  \\\n",
       "0       118.HR.9124  2024-07-24 00:00:00   True   \n",
       "1       118.HR.8667  2024-06-07 00:00:00   True   \n",
       "2       119.HJRES.9  2025-01-03 00:00:00  False   \n",
       "3       119.HJRES.8  2025-01-03 00:00:00  False   \n",
       "4       119.HJRES.2  2025-01-03 00:00:00  False   \n",
       "...             ...                  ...    ...   \n",
       "13807  113.HJRES.54  2013-07-24 00:00:00  False   \n",
       "13808  113.HJRES.53  2013-07-24 00:00:00  False   \n",
       "13809  113.HJRES.52  2013-07-24 00:00:00  False   \n",
       "13810    113.S.1504  2013-09-12 00:00:00  False   \n",
       "13811  113.HJRES.61  2013-09-11 00:00:00  False   \n",
       "\n",
       "                                               full_text  \n",
       "0      <html><body><pre>\\n[118th Congress Public Law ...  \n",
       "1      <html><body><pre>\\n[118th Congress Public Law ...  \n",
       "2      <html><body><pre>\\n[Congressional Bills 119th ...  \n",
       "3      <html><body><pre>\\n[Congressional Bills 119th ...  \n",
       "4      <html><body><pre>\\n[Congressional Bills 119th ...  \n",
       "...                                                  ...  \n",
       "13807  <html><body><pre>\\n[Congressional Bills 113th ...  \n",
       "13808  <html><body><pre>\\n[Congressional Bills 113th ...  \n",
       "13809  <html><body><pre>\\n[Congressional Bills 113th ...  \n",
       "13810  <html><body><pre>\\n[Congressional Bills 113th ...  \n",
       "13811  <html><body><pre>\\n[Congressional Bills 113th ...  \n",
       "\n",
       "[13812 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bills_all = pd.read_csv(p + r\"bill_id_law_text.csv\", dtype=str)\n",
    "\n",
    "print(bills_all.shape)\n",
    "bills_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8542a596",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<html><body><pre>\\n[118th Congress Public Law 259]\\n[From the U.S. Government Publishing Office]\\n\\n\\n\\n[[Page 138 STAT. 2973]]\\n\\nPublic Law 118-259\\n118th Congress\\n\\n                                 An Act\\n\\n\\n \\n To name the Department of Veterans Affairs community-based outpatient \\n       clinic in Auburn, California, as the ``Louis A. Conter VA \\n            Clinic''. &lt;&lt;NOTE: Jan. 4, 2025 -  [H.R. 9124]&gt;&gt; \\n\\n    Be it enacted by the Senate and House of Representatives of the \\nUnited States of America in Congress assembled,\\nSECTION 1. FINDINGS.\\n\\n    Congress finds the following:\\n            (1) Louis ``Lou'' Anthony Conter was born on September 13, \\n        1921, in Ojibwa, Wisconsin.\\n            (2) Lt. Commander Lou Conter, the last remaining survivor of \\n        the attack on the USS Arizona at Pearl Harbor, was an American \\n        hero.\\n            (3) On that fearful day, Petty Officer Conter helped \\n        evacuate shipmates who were blinded, wounded, or burned, even \\n        restraining some of his fellow shipmates from jumping overboard \\n        into the burning sea.\\n            (4) In the days after the attack, he helped with recovering \\n        bodies and putting out fires. Lou Conter's heroic actions saved \\n        the lives of many of his shipmates on December 7, 1941.\\n            (5) Following Pearl Harbor, Conter continued serving during \\n        WWII in New Guinea and in Europe as an enlisted naval aviation \\n        pilot assigned to VP-11, a ``Black Cat'' Squadron.\\n            (6) Lou Conter would be awarded with the Distinguished \\n        Flying Cross for actively taking part in the rescue of 219 \\n        Australians trapped by Japanese troops in New Guinea.\\n            (7) Later, in the Korean War, he served on the USS Bon Homme \\n        Richard as both an intelligence officer and a navy aviation \\n        pilot. Following his service in the Korean War, he served as a \\n        military intelligence advisor to three Presidents: Dwight D. \\n        Eisenhower, John F. Kennedy, and Lyndon B. Johnson.\\n            (8) During the 1950s, Lou Conter played a prominent role in \\n        the establishment and development of the Navy Survival, Evasion, \\n        Resistance and Escape (SERE) training program.\\n            (9) In addition to the Distinguished Flying Cross, he was \\n        awarded the Navy Commendation Medal and became the first \\n        recipient of the USS Arizona Medal of Freedom.\\n            (10) Louis Conter retired from the Navy in 1967 after \\n        serving 28 years as a Lieutenant Commander.\\n            (11) Following his retirement, he generously gave his time \\n        to share his personal experiences at veterans' ceremonies and by \\n        giving lectures to students.\\n\\n[[Page 138 STAT. 2974]]\\n\\n            (12) Lieutenant Commander Conter's lectures were popular \\n        with generations of local students who were equally fascinated \\n        and enthralled by his first-person accounts.\\n            (13) He is eminently deserving of recognition for his \\n        decades of service to a grateful nation.\\n            (14) Lieutenant Commander Conter passed away in Grass \\n        Valley, California on April 1, 2024.\\nSEC. 2. NAME OF DEPARTMENT OF VETERANS AFFAIRS COMMUNITY-BASED \\n                    OUTPATIENT CLINIC, AUBURN, CALIFORNIA.\\n\\n    The Department of Veterans Affairs community-based outpatient clinic \\nin Auburn, California, shall after the date of the enactment of this Act \\nbe known and designated as the ``Louis A. Conter VA Clinic''. Any \\nreference to such clinic in any law, regulation, map, document, record, \\nor other paper of the United States shall be considered to be a \\nreference to the Louis A. Conter VA Clinic.\\n\\n    Approved January 4, 2025.\\n\\nLEGISLATIVE HISTORY--H.R. 9124:\\n---------------------------------------------------------------------------\\n\\nCONGRESSIONAL RECORD, Vol. 170 (2024):\\n            Dec. 16, considered and passed House.\\n            Dec. 20, considered and passed Senate.\\n\\n                                  &lt;all&gt;\\n</pre></body></html>\\n\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bills_all.iloc[0]['full_text'][:10000]  # Display the first 10000 characters of the law text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d9e83c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "law\n",
       "False    13767\n",
       "True        45\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bills_all[\"law\"].value_counts()  # Check the distribution of the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c645dd55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13812 entries, 0 to 13811\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   id         13812 non-null  object\n",
      " 1   date       13812 non-null  object\n",
      " 2   law        13812 non-null  object\n",
      " 3   full_text  13812 non-null  object\n",
      "dtypes: object(4)\n",
      "memory usage: 431.8+ KB\n"
     ]
    }
   ],
   "source": [
    "bills_all.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b014c4",
   "metadata": {},
   "source": [
    "# 1b. Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "97ce5239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 4)\n"
     ]
    }
   ],
   "source": [
    "# original counts\n",
    "counts = bills_all[\"law\"].value_counts()\n",
    "\n",
    "total = counts.sum()\n",
    "law_ratio = counts[\"True\"] / total   # ~0.0033\n",
    "\n",
    "n_total = 1000\n",
    "\n",
    "# target sizes preserving true imbalance\n",
    "n_law = max(1, int(law_ratio * n_total))\n",
    "n_nolaw = n_total - n_law\n",
    "\n",
    "# split classes\n",
    "law = bills_all[bills_all[\"law\"] == \"True\"]\n",
    "nolaw = bills_all[bills_all[\"law\"] == \"False\"]\n",
    "\n",
    "# sample\n",
    "law_s = law.sample(n=n_law, random_state=42, replace=False)\n",
    "nolaw_s = nolaw.sample(n=n_nolaw, random_state=42, replace=False)\n",
    "\n",
    "# merge + shuffle\n",
    "sample = (\n",
    "    pd.concat([law_s, nolaw_s])\n",
    "    .sample(frac=1, random_state=42)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "print(sample.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1ba347ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "law\n",
      "False    997\n",
      "True       3\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(sample[\"law\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bdc6861a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "law\n",
      "False    0.997\n",
      "True     0.003\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(sample[\"law\"].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aff43381",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.to_csv(p + r\"bill_id_law_text_sample_5000.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec23ab7",
   "metadata": {},
   "source": [
    "# 2. Data engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffcd2208",
   "metadata": {},
   "source": [
    "Already have `id, date, law, full_text`. Add structured stuff from id and date.\n",
    "\n",
    "## 2.1 Parse id into structured columns\n",
    "\n",
    "id examples:\n",
    "\n",
    "`118.HR.9124`\n",
    "\n",
    "`113.S.1504`\n",
    "\n",
    "`119.HJRES.9`\n",
    "\n",
    "I want:\n",
    "\n",
    "* congress (int)\n",
    "\n",
    "* chamber (H or S)\n",
    "\n",
    "* bill_type (HR, HJRES, S, etc.)\n",
    "\n",
    "* bill_number (int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f94627ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>law</th>\n",
       "      <th>full_text</th>\n",
       "      <th>congress</th>\n",
       "      <th>bill_type</th>\n",
       "      <th>bill_number</th>\n",
       "      <th>chamber</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>118.HR.9124</td>\n",
       "      <td>2024-07-24 00:00:00</td>\n",
       "      <td>True</td>\n",
       "      <td>&lt;html&gt;&lt;body&gt;&lt;pre&gt;\\n[118th Congress Public Law ...</td>\n",
       "      <td>118</td>\n",
       "      <td>HR</td>\n",
       "      <td>9124</td>\n",
       "      <td>House</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>118.HR.8667</td>\n",
       "      <td>2024-06-07 00:00:00</td>\n",
       "      <td>True</td>\n",
       "      <td>&lt;html&gt;&lt;body&gt;&lt;pre&gt;\\n[118th Congress Public Law ...</td>\n",
       "      <td>118</td>\n",
       "      <td>HR</td>\n",
       "      <td>8667</td>\n",
       "      <td>House</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>119.HJRES.9</td>\n",
       "      <td>2025-01-03 00:00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>&lt;html&gt;&lt;body&gt;&lt;pre&gt;\\n[Congressional Bills 119th ...</td>\n",
       "      <td>119</td>\n",
       "      <td>HJRES</td>\n",
       "      <td>9</td>\n",
       "      <td>House</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>119.HJRES.8</td>\n",
       "      <td>2025-01-03 00:00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>&lt;html&gt;&lt;body&gt;&lt;pre&gt;\\n[Congressional Bills 119th ...</td>\n",
       "      <td>119</td>\n",
       "      <td>HJRES</td>\n",
       "      <td>8</td>\n",
       "      <td>House</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>119.HJRES.2</td>\n",
       "      <td>2025-01-03 00:00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>&lt;html&gt;&lt;body&gt;&lt;pre&gt;\\n[Congressional Bills 119th ...</td>\n",
       "      <td>119</td>\n",
       "      <td>HJRES</td>\n",
       "      <td>2</td>\n",
       "      <td>House</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13807</th>\n",
       "      <td>113.HJRES.54</td>\n",
       "      <td>2013-07-24 00:00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>&lt;html&gt;&lt;body&gt;&lt;pre&gt;\\n[Congressional Bills 113th ...</td>\n",
       "      <td>113</td>\n",
       "      <td>HJRES</td>\n",
       "      <td>54</td>\n",
       "      <td>House</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13808</th>\n",
       "      <td>113.HJRES.53</td>\n",
       "      <td>2013-07-24 00:00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>&lt;html&gt;&lt;body&gt;&lt;pre&gt;\\n[Congressional Bills 113th ...</td>\n",
       "      <td>113</td>\n",
       "      <td>HJRES</td>\n",
       "      <td>53</td>\n",
       "      <td>House</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13809</th>\n",
       "      <td>113.HJRES.52</td>\n",
       "      <td>2013-07-24 00:00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>&lt;html&gt;&lt;body&gt;&lt;pre&gt;\\n[Congressional Bills 113th ...</td>\n",
       "      <td>113</td>\n",
       "      <td>HJRES</td>\n",
       "      <td>52</td>\n",
       "      <td>House</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13810</th>\n",
       "      <td>113.S.1504</td>\n",
       "      <td>2013-09-12 00:00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>&lt;html&gt;&lt;body&gt;&lt;pre&gt;\\n[Congressional Bills 113th ...</td>\n",
       "      <td>113</td>\n",
       "      <td>S</td>\n",
       "      <td>1504</td>\n",
       "      <td>Senate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13811</th>\n",
       "      <td>113.HJRES.61</td>\n",
       "      <td>2013-09-11 00:00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>&lt;html&gt;&lt;body&gt;&lt;pre&gt;\\n[Congressional Bills 113th ...</td>\n",
       "      <td>113</td>\n",
       "      <td>HJRES</td>\n",
       "      <td>61</td>\n",
       "      <td>House</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13812 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                 date    law  \\\n",
       "0       118.HR.9124  2024-07-24 00:00:00   True   \n",
       "1       118.HR.8667  2024-06-07 00:00:00   True   \n",
       "2       119.HJRES.9  2025-01-03 00:00:00  False   \n",
       "3       119.HJRES.8  2025-01-03 00:00:00  False   \n",
       "4       119.HJRES.2  2025-01-03 00:00:00  False   \n",
       "...             ...                  ...    ...   \n",
       "13807  113.HJRES.54  2013-07-24 00:00:00  False   \n",
       "13808  113.HJRES.53  2013-07-24 00:00:00  False   \n",
       "13809  113.HJRES.52  2013-07-24 00:00:00  False   \n",
       "13810    113.S.1504  2013-09-12 00:00:00  False   \n",
       "13811  113.HJRES.61  2013-09-11 00:00:00  False   \n",
       "\n",
       "                                               full_text  congress bill_type  \\\n",
       "0      <html><body><pre>\\n[118th Congress Public Law ...       118        HR   \n",
       "1      <html><body><pre>\\n[118th Congress Public Law ...       118        HR   \n",
       "2      <html><body><pre>\\n[Congressional Bills 119th ...       119     HJRES   \n",
       "3      <html><body><pre>\\n[Congressional Bills 119th ...       119     HJRES   \n",
       "4      <html><body><pre>\\n[Congressional Bills 119th ...       119     HJRES   \n",
       "...                                                  ...       ...       ...   \n",
       "13807  <html><body><pre>\\n[Congressional Bills 113th ...       113     HJRES   \n",
       "13808  <html><body><pre>\\n[Congressional Bills 113th ...       113     HJRES   \n",
       "13809  <html><body><pre>\\n[Congressional Bills 113th ...       113     HJRES   \n",
       "13810  <html><body><pre>\\n[Congressional Bills 113th ...       113         S   \n",
       "13811  <html><body><pre>\\n[Congressional Bills 113th ...       113     HJRES   \n",
       "\n",
       "       bill_number chamber  \n",
       "0             9124   House  \n",
       "1             8667   House  \n",
       "2                9   House  \n",
       "3                8   House  \n",
       "4                2   House  \n",
       "...            ...     ...  \n",
       "13807           54   House  \n",
       "13808           53   House  \n",
       "13809           52   House  \n",
       "13810         1504  Senate  \n",
       "13811           61   House  \n",
       "\n",
       "[13812 rows x 8 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def parse_id(bill_id):\n",
    "    # Example patterns: 118.HR.9124  or  119.HJRES.9\n",
    "    m = re.match(r\"(\\d+)\\.([A-Z]+)\\.(\\d+)\", bill_id)\n",
    "    if not m:\n",
    "        return pd.Series([None, None, None, None], \n",
    "                         index=[\"congress\", \"bill_type\", \"bill_number\", \"chamber\"])\n",
    "    congress = int(m.group(1))\n",
    "    bill_type = m.group(2)\n",
    "    bill_number = int(m.group(3))\n",
    "    \n",
    "    # crude chamber mapping\n",
    "    if bill_type.startswith(\"H\"):\n",
    "        chamber = \"House\"\n",
    "    elif bill_type.startswith(\"S\"):\n",
    "        chamber = \"Senate\"\n",
    "    else:\n",
    "        chamber = None\n",
    "    \n",
    "    return pd.Series([congress, bill_type, bill_number, chamber],\n",
    "                     index=[\"congress\", \"bill_type\", \"bill_number\", \"chamber\"])\n",
    "\n",
    "parsed = bills[\"id\"].apply(parse_id)\n",
    "bills = pd.concat([bills, parsed], axis=1)\n",
    "# bills = bills.loc[:, ~bills.columns.duplicated()]\n",
    "bills"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba82fbba",
   "metadata": {},
   "source": [
    "##  2.2 Explicit label column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3d1e2b5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0         True\n",
       "1         True\n",
       "2        False\n",
       "3        False\n",
       "4        False\n",
       "         ...  \n",
       "13807    False\n",
       "13808    False\n",
       "13809    False\n",
       "13810    False\n",
       "13811    False\n",
       "Name: law, Length: 13812, dtype: object"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(bills[\"law\"].dtype)\n",
    "bills[\"law\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c60406b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        1\n",
       "1        1\n",
       "2        0\n",
       "3        0\n",
       "4        0\n",
       "        ..\n",
       "13807    0\n",
       "13808    0\n",
       "13809    0\n",
       "13810    0\n",
       "13811    0\n",
       "Name: label, Length: 13812, dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bills[\"label\"] = bills[\"law\"].astype(str).map({\"True\": 1, \"False\": 0}).astype(int) # True -> 1, False -> 0\n",
    "bills[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "166a6c41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    13767\n",
       "1       45\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bills[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f572d5a7",
   "metadata": {},
   "source": [
    "## 2.3 Time-based features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "378f2289",
   "metadata": {},
   "outputs": [],
   "source": [
    "bills[\"date\"] = pd.to_datetime(bills[\"date\"])\n",
    "bills[\"year\"] = bills[\"date\"].dt.year\n",
    "bills[\"month\"] = bills[\"date\"].dt.month\n",
    "bills[\"day_of_year\"] = bills[\"date\"].dt.dayofyear"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecbc00a1",
   "metadata": {},
   "source": [
    "# 3. Text Preprocessing and Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "16a39076",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>law</th>\n",
       "      <th>full_text</th>\n",
       "      <th>congress</th>\n",
       "      <th>bill_type</th>\n",
       "      <th>bill_number</th>\n",
       "      <th>chamber</th>\n",
       "      <th>label</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_year</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>118.HR.9124</td>\n",
       "      <td>2024-07-24</td>\n",
       "      <td>True</td>\n",
       "      <td>&lt;html&gt;&lt;body&gt;&lt;pre&gt;\\n[118th Congress Public Law ...</td>\n",
       "      <td>118</td>\n",
       "      <td>HR</td>\n",
       "      <td>9124</td>\n",
       "      <td>House</td>\n",
       "      <td>1</td>\n",
       "      <td>2024</td>\n",
       "      <td>7</td>\n",
       "      <td>206</td>\n",
       "      <td>Public Law 118-259 118th Congress An Act To na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>118.HR.8667</td>\n",
       "      <td>2024-06-07</td>\n",
       "      <td>True</td>\n",
       "      <td>&lt;html&gt;&lt;body&gt;&lt;pre&gt;\\n[118th Congress Public Law ...</td>\n",
       "      <td>118</td>\n",
       "      <td>HR</td>\n",
       "      <td>8667</td>\n",
       "      <td>House</td>\n",
       "      <td>1</td>\n",
       "      <td>2024</td>\n",
       "      <td>6</td>\n",
       "      <td>159</td>\n",
       "      <td>Public Law 118-251 118th Congress An Act To re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>119.HJRES.9</td>\n",
       "      <td>2025-01-03</td>\n",
       "      <td>False</td>\n",
       "      <td>&lt;html&gt;&lt;body&gt;&lt;pre&gt;\\n[Congressional Bills 119th ...</td>\n",
       "      <td>119</td>\n",
       "      <td>HJRES</td>\n",
       "      <td>9</td>\n",
       "      <td>House</td>\n",
       "      <td>0</td>\n",
       "      <td>2025</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>&lt;DOC&gt; 119th CONGRESS 1st Session H. J. RES. 9 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>119.HJRES.8</td>\n",
       "      <td>2025-01-03</td>\n",
       "      <td>False</td>\n",
       "      <td>&lt;html&gt;&lt;body&gt;&lt;pre&gt;\\n[Congressional Bills 119th ...</td>\n",
       "      <td>119</td>\n",
       "      <td>HJRES</td>\n",
       "      <td>8</td>\n",
       "      <td>House</td>\n",
       "      <td>0</td>\n",
       "      <td>2025</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>&lt;DOC&gt; 119th CONGRESS 1st Session H. J. RES. 8 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>119.HJRES.2</td>\n",
       "      <td>2025-01-03</td>\n",
       "      <td>False</td>\n",
       "      <td>&lt;html&gt;&lt;body&gt;&lt;pre&gt;\\n[Congressional Bills 119th ...</td>\n",
       "      <td>119</td>\n",
       "      <td>HJRES</td>\n",
       "      <td>2</td>\n",
       "      <td>House</td>\n",
       "      <td>0</td>\n",
       "      <td>2025</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>&lt;DOC&gt; 119th CONGRESS 1st Session H. J. RES. 2 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id       date    law  \\\n",
       "0  118.HR.9124 2024-07-24   True   \n",
       "1  118.HR.8667 2024-06-07   True   \n",
       "2  119.HJRES.9 2025-01-03  False   \n",
       "3  119.HJRES.8 2025-01-03  False   \n",
       "4  119.HJRES.2 2025-01-03  False   \n",
       "\n",
       "                                           full_text  congress bill_type  \\\n",
       "0  <html><body><pre>\\n[118th Congress Public Law ...       118        HR   \n",
       "1  <html><body><pre>\\n[118th Congress Public Law ...       118        HR   \n",
       "2  <html><body><pre>\\n[Congressional Bills 119th ...       119     HJRES   \n",
       "3  <html><body><pre>\\n[Congressional Bills 119th ...       119     HJRES   \n",
       "4  <html><body><pre>\\n[Congressional Bills 119th ...       119     HJRES   \n",
       "\n",
       "   bill_number chamber  label  year  month  day_of_year  \\\n",
       "0         9124   House      1  2024      7          206   \n",
       "1         8667   House      1  2024      6          159   \n",
       "2            9   House      0  2025      1            3   \n",
       "3            8   House      0  2025      1            3   \n",
       "4            2   House      0  2025      1            3   \n",
       "\n",
       "                                          clean_text  \n",
       "0  Public Law 118-259 118th Congress An Act To na...  \n",
       "1  Public Law 118-251 118th Congress An Act To re...  \n",
       "2  <DOC> 119th CONGRESS 1st Session H. J. RES. 9 ...  \n",
       "3  <DOC> 119th CONGRESS 1st Session H. J. RES. 8 ...  \n",
       "4  <DOC> 119th CONGRESS 1st Session H. J. RES. 2 ...  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_bill_text(raw_html):\n",
    "    # 1. Remove HTML tags\n",
    "    text = BeautifulSoup(raw_html, \"html.parser\").get_text(separator=\" \")\n",
    "\n",
    "    # 2. Remove escaped entities (like &lt;&lt;, &gt;&gt;)\n",
    "    text = re.sub(r\"&[a-z]+;\", \" \", text)\n",
    "\n",
    "    # 3. Remove bracketed junk (page numbers, notes, etc.)\n",
    "    text = re.sub(r\"\\[\\[.*?\\]\\]\", \" \", text)\n",
    "    text = re.sub(r\"\\[.*?\\]\", \" \", text)\n",
    "\n",
    "    # 4. Collapse multiple whitespaces/newlines\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "\n",
    "    # 5. Trim\n",
    "    return text.strip()\n",
    "\n",
    "bills[\"clean_text\"] = bills[\"full_text\"].apply(clean_bill_text)\n",
    "bills.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d5663837",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Public Law 118-259 118th Congress An Act To name the Department of Veterans Affairs community-based outpatient clinic in Auburn, California, as the ``Louis A. Conter VA Clinic''. <<NOTE: Jan. 4, 2025 - >> Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. FINDINGS. Congress finds the following: (1) Louis ``Lou'' Anthony Conter was born on September 13, 1921, in Ojibwa, Wisconsin. (2) Lt. Commander Lou Conter, the last remaining survivor of the attack on the USS Arizona at Pearl Harbor, was an American hero. (3) On that fearful day, Petty Officer Conter helped evacuate shipmates who were blinded, wounded, or burned, even restraining some of his fellow shipmates from jumping overboard into the burning sea. (4) In the days after the attack, he helped with recovering bodies and putting out fires. Lou Conter's heroic actions saved the lives of many of his shipmates on December 7, 1941. (5) Following Pearl Harbor, Conter continued serving during WWII in New Guinea and in Europe as an enlisted naval aviation pilot assigned to VP-11, a ``Black Cat'' Squadron. (6) Lou Conter would be awarded with the Distinguished Flying Cross for actively taking part in the rescue of 219 Australians trapped by Japanese troops in New Guinea. (7) Later, in the Korean War, he served on the USS Bon Homme Richard as both an intelligence officer and a navy aviation pilot. Following his service in the Korean War, he served as a military intelligence advisor to three Presidents: Dwight D. Eisenhower, John F. Kennedy, and Lyndon B. Johnson. (8) During the 1950s, Lou Conter played a prominent role in the establishment and development of the Navy Survival, Evasion, Resistance and Escape (SERE) training program. (9) In addition to the Distinguished Flying Cross, he was awarded the Navy Commendation Medal and became the first recipient of the USS Arizona Medal of Freedom. (10) Louis Conter retired from the Navy in 1967 after serving 28 years as a Lieutenant Commander. (11) Following his retirement, he generously gave his time to share his personal experiences at veterans' ceremonies and by giving lectures to students. (12) Lieutenant Commander Conter's lectures were popular with generations of local students who were equally fascinated and enthralled by his first-person accounts. (13) He is eminently deserving of recognition for his decades of service to a grateful nation. (14) Lieutenant Commander Conter passed away in Grass Valley, California on April 1, 2024. SEC. 2. NAME OF DEPARTMENT OF VETERANS AFFAIRS COMMUNITY-BASED OUTPATIENT CLINIC, AUBURN, CALIFORNIA. The Department of Veterans Affairs community-based outpatient clinic in Auburn, California, shall after the date of the enactment of this Act be known and designated as the ``Louis A. Conter VA Clinic''. Any reference to such clinic in any law, regulation, map, document, record, or other paper of the United States shall be considered to be a reference to the Louis A. Conter VA Clinic. Approved January 4, 2025. LEGISLATIVE HISTORY--H.R. 9124: --------------------------------------------------------------------------- CONGRESSIONAL RECORD, Vol. 170 (2024): Dec. 16, considered and passed House. Dec. 20, considered and passed Senate. <all>\""
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bills.iloc[0]['clean_text'][:10000]  # Display the first 10000 characters of the law text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f95292ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. HTML → raw text\n",
    "\n",
    "def strip_html(raw_html: str) -> str:\n",
    "    if not isinstance(raw_html, str):\n",
    "        return \"\"\n",
    "    text = BeautifulSoup(raw_html, \"html.parser\").get_text(separator=\" \")\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    return text.strip()\n",
    "\n",
    "# 2. Domain-specific cleanup\n",
    "\n",
    "def normalize_bill_text(text: str) -> str:\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "\n",
    "    # Remove NOTE blocks like <<NOTE: ... >>\n",
    "    text = re.sub(r\"<<.*?>>\", \" \", text)\n",
    "\n",
    "    # Remove HTML-ish debris like <all>\n",
    "    text = re.sub(r\"<all>\", \" \", text, flags=re.IGNORECASE)\n",
    "\n",
    "    # Remove page/stat markers: [[Page 138 STAT. 2973]], [118th Congress Public Law ...], etc.\n",
    "    text = re.sub(r\"\\[\\[.*?\\]\\]\", \" \", text)\n",
    "    text = re.sub(r\"\\[[^\\]]*STAT\\.[^\\]]*\\]\", \" \", text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r\"\\[From the U\\.S\\. Government Publishing Office\\]\", \" \", text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r\"\\[118th Congress Public Law.*?\\]\", \" \", text, flags=re.IGNORECASE)\n",
    "\n",
    "    # Kill LEGISLATIVE HISTORY and everything after (procedural, not semantic)\n",
    "    text = re.sub(r\"LEGISLATIVE HISTORY[\\s\\S]*$\", \" \", text, flags=re.IGNORECASE)\n",
    "\n",
    "    # Normalize repeated backticks/quotes\n",
    "    text = text.replace(\"``\", '\"').replace(\"''\", '\"')\n",
    "\n",
    "    # Mild boilerplate simplification:\n",
    "    # compress \"Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled,\"\n",
    "    text = re.sub(\n",
    "        r\"Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled,?\",\n",
    "        \"Be it enacted,\",\n",
    "        text,\n",
    "        flags=re.IGNORECASE\n",
    "    )\n",
    "\n",
    "    # Remove insane whitespace / leftover punctuation clutter\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    text = re.sub(r\"\\s+([,.;:])\", r\"\\1\", text)\n",
    "\n",
    "    return text.strip()\n",
    "\n",
    "# 3. Apply to all bills\n",
    "\n",
    "bills[\"clean_text\"] = (\n",
    "    bills[\"full_text\"]\n",
    "    .astype(str)\n",
    "    .apply(strip_html)\n",
    "    .apply(normalize_bill_text)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "de84f2a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>law</th>\n",
       "      <th>full_text</th>\n",
       "      <th>congress</th>\n",
       "      <th>bill_type</th>\n",
       "      <th>bill_number</th>\n",
       "      <th>chamber</th>\n",
       "      <th>label</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_year</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>118.HR.9124</td>\n",
       "      <td>2024-07-24</td>\n",
       "      <td>True</td>\n",
       "      <td>&lt;html&gt;&lt;body&gt;&lt;pre&gt;\\n[118th Congress Public Law ...</td>\n",
       "      <td>118</td>\n",
       "      <td>HR</td>\n",
       "      <td>9124</td>\n",
       "      <td>House</td>\n",
       "      <td>1</td>\n",
       "      <td>2024</td>\n",
       "      <td>7</td>\n",
       "      <td>206</td>\n",
       "      <td>Public Law 118-259 118th Congress An Act To na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>118.HR.8667</td>\n",
       "      <td>2024-06-07</td>\n",
       "      <td>True</td>\n",
       "      <td>&lt;html&gt;&lt;body&gt;&lt;pre&gt;\\n[118th Congress Public Law ...</td>\n",
       "      <td>118</td>\n",
       "      <td>HR</td>\n",
       "      <td>8667</td>\n",
       "      <td>House</td>\n",
       "      <td>1</td>\n",
       "      <td>2024</td>\n",
       "      <td>6</td>\n",
       "      <td>159</td>\n",
       "      <td>Public Law 118-251 118th Congress An Act To re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>119.HJRES.9</td>\n",
       "      <td>2025-01-03</td>\n",
       "      <td>False</td>\n",
       "      <td>&lt;html&gt;&lt;body&gt;&lt;pre&gt;\\n[Congressional Bills 119th ...</td>\n",
       "      <td>119</td>\n",
       "      <td>HJRES</td>\n",
       "      <td>9</td>\n",
       "      <td>House</td>\n",
       "      <td>0</td>\n",
       "      <td>2025</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>[Congressional Bills 119th Congress] [H.J. Res...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>119.HJRES.8</td>\n",
       "      <td>2025-01-03</td>\n",
       "      <td>False</td>\n",
       "      <td>&lt;html&gt;&lt;body&gt;&lt;pre&gt;\\n[Congressional Bills 119th ...</td>\n",
       "      <td>119</td>\n",
       "      <td>HJRES</td>\n",
       "      <td>8</td>\n",
       "      <td>House</td>\n",
       "      <td>0</td>\n",
       "      <td>2025</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>[Congressional Bills 119th Congress] [H.J. Res...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>119.HJRES.2</td>\n",
       "      <td>2025-01-03</td>\n",
       "      <td>False</td>\n",
       "      <td>&lt;html&gt;&lt;body&gt;&lt;pre&gt;\\n[Congressional Bills 119th ...</td>\n",
       "      <td>119</td>\n",
       "      <td>HJRES</td>\n",
       "      <td>2</td>\n",
       "      <td>House</td>\n",
       "      <td>0</td>\n",
       "      <td>2025</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>[Congressional Bills 119th Congress] [H.J. Res...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id       date    law  \\\n",
       "0  118.HR.9124 2024-07-24   True   \n",
       "1  118.HR.8667 2024-06-07   True   \n",
       "2  119.HJRES.9 2025-01-03  False   \n",
       "3  119.HJRES.8 2025-01-03  False   \n",
       "4  119.HJRES.2 2025-01-03  False   \n",
       "\n",
       "                                           full_text  congress bill_type  \\\n",
       "0  <html><body><pre>\\n[118th Congress Public Law ...       118        HR   \n",
       "1  <html><body><pre>\\n[118th Congress Public Law ...       118        HR   \n",
       "2  <html><body><pre>\\n[Congressional Bills 119th ...       119     HJRES   \n",
       "3  <html><body><pre>\\n[Congressional Bills 119th ...       119     HJRES   \n",
       "4  <html><body><pre>\\n[Congressional Bills 119th ...       119     HJRES   \n",
       "\n",
       "   bill_number chamber  label  year  month  day_of_year  \\\n",
       "0         9124   House      1  2024      7          206   \n",
       "1         8667   House      1  2024      6          159   \n",
       "2            9   House      0  2025      1            3   \n",
       "3            8   House      0  2025      1            3   \n",
       "4            2   House      0  2025      1            3   \n",
       "\n",
       "                                          clean_text  \n",
       "0  Public Law 118-259 118th Congress An Act To na...  \n",
       "1  Public Law 118-251 118th Congress An Act To re...  \n",
       "2  [Congressional Bills 119th Congress] [H.J. Res...  \n",
       "3  [Congressional Bills 119th Congress] [H.J. Res...  \n",
       "4  [Congressional Bills 119th Congress] [H.J. Res...  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bills.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "74de1d8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Public Law 118-259 118th Congress An Act To name the Department of Veterans Affairs community-based outpatient clinic in Auburn, California, as the \"Louis A. Conter VA Clinic\". Be it enacted, SECTION 1. FINDINGS. Congress finds the following: (1) Louis \"Lou\" Anthony Conter was born on September 13, 1921, in Ojibwa, Wisconsin. (2) Lt. Commander Lou Conter, the last remaining survivor of the attack on the USS Arizona at Pearl Harbor, was an American hero. (3) On that fearful day, Petty Officer Conter helped evacuate shipmates who were blinded, wounded, or burned, even restraining some of his fellow shipmates from jumping overboard into the burning sea. (4) In the days after the attack, he helped with recovering bodies and putting out fires. Lou Conter\\'s heroic actions saved the lives of many of his shipmates on December 7, 1941. (5) Following Pearl Harbor, Conter continued serving during WWII in New Guinea and in Europe as an enlisted naval aviation pilot assigned to VP-11, a \"Black Cat\" Squadron. (6) Lou Conter would be awarded with the Distinguished Flying Cross for actively taking part in the rescue of 219 Australians trapped by Japanese troops in New Guinea. (7) Later, in the Korean War, he served on the USS Bon Homme Richard as both an intelligence officer and a navy aviation pilot. Following his service in the Korean War, he served as a military intelligence advisor to three Presidents: Dwight D. Eisenhower, John F. Kennedy, and Lyndon B. Johnson. (8) During the 1950s, Lou Conter played a prominent role in the establishment and development of the Navy Survival, Evasion, Resistance and Escape (SERE) training program. (9) In addition to the Distinguished Flying Cross, he was awarded the Navy Commendation Medal and became the first recipient of the USS Arizona Medal of Freedom. (10) Louis Conter retired from the Navy in 1967 after serving 28 years as a Lieutenant Commander. (11) Following his retirement, he generously gave his time to share his personal experiences at veterans\\' ceremonies and by giving lectures to students. (12) Lieutenant Commander Conter\\'s lectures were popular with generations of local students who were equally fascinated and enthralled by his first-person accounts. (13) He is eminently deserving of recognition for his decades of service to a grateful nation. (14) Lieutenant Commander Conter passed away in Grass Valley, California on April 1, 2024. SEC. 2. NAME OF DEPARTMENT OF VETERANS AFFAIRS COMMUNITY-BASED OUTPATIENT CLINIC, AUBURN, CALIFORNIA. The Department of Veterans Affairs community-based outpatient clinic in Auburn, California, shall after the date of the enactment of this Act be known and designated as the \"Louis A. Conter VA Clinic\". Any reference to such clinic in any law, regulation, map, document, record, or other paper of the United States shall be considered to be a reference to the Louis A. Conter VA Clinic. Approved January 4, 2025.'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bills.iloc[0]['clean_text'][:10000]  # Display the first 10000 characters of the law text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ab5c03ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contractions (harmless to keep; rare in bills)\n",
    "contractions = {\n",
    "    \"can't\": \"cannot\", \"won't\": \"will not\", \"i'm\": \"i am\", \"it's\": \"it is\",\n",
    "    \"don't\": \"do not\", \"didn't\": \"did not\", \"doesn't\": \"does not\",\n",
    "    \"i've\": \"i have\", \"i'd\": \"i would\", \"i'll\": \"i will\", \"you're\": \"you are\",\n",
    "    \"we're\": \"we are\", \"they're\": \"they are\", \"isn't\": \"is not\", \"aren't\": \"are not\",\n",
    "    \"wasn't\": \"was not\", \"weren't\": \"were not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
    "    \"hadn't\": \"had not\", \"shouldn't\": \"should not\", \"wouldn't\": \"would not\",\n",
    "    \"couldn't\": \"could not\", \"mustn't\": \"must not\", \"mightn't\": \"might not\",\n",
    "    \"shan't\": \"shall not\", \"let's\": \"let us\", \"that's\": \"that is\", \"who's\": \"who is\",\n",
    "    \"what's\": \"what is\", \"here's\": \"here is\", \"there's\": \"there is\", \"how's\": \"how is\"\n",
    "}\n",
    "contractions_re = re.compile(\"(%s)\" % \"|\".join(map(re.escape, contractions.keys())), flags=re.IGNORECASE)\n",
    "\n",
    "# Boilerplate / low-signal phrases specific to bills\n",
    "boilerplate_phrases = [\n",
    "    # enactment & stock openings\n",
    "    \"be it enacted by the senate and house of representatives of the united states of america in congress assembled\",\n",
    "    \"be it enacted by the senate and house of representatives in congress assembled\",\n",
    "    \"be it enacted,\",\n",
    "    \"a bill to\",\n",
    "    \"an act to\",\n",
    "    \"an act\",\n",
    "    # headings that rarely add model-usable semantics\n",
    "    \"section 1. short title\",\n",
    "    \"short title\",\n",
    "    \"table of contents\",\n",
    "]\n",
    "\n",
    "# Tail sections that are mostly procedural\n",
    "tail_triggers = [\n",
    "    \"legislative history\",\n",
    "    \"calendar no.\",\n",
    "    \"attest:\",\n",
    "]\n",
    "\n",
    "def expand_contractions(text: str) -> str:\n",
    "    def repl(m):\n",
    "        original = m.group(0)\n",
    "        key = original.lower()\n",
    "        out = contractions.get(key)\n",
    "        if not out:\n",
    "            return original\n",
    "        # Preserve capitalization if contraction starts sentence / proper\n",
    "        return out.capitalize() if original[0].isupper() else out\n",
    "    return contractions_re.sub(repl, text)\n",
    "\n",
    "def strip_html(raw_html: str) -> str:\n",
    "    if not isinstance(raw_html, str):\n",
    "        return \"\"\n",
    "    text = BeautifulSoup(raw_html, \"html.parser\").get_text(separator=\" \")\n",
    "    return text\n",
    "\n",
    "def clean_bill_text(text: str) -> str:\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "\n",
    "    # 1. Contractions (mostly no-ops here, but safe)\n",
    "    text = expand_contractions(text)\n",
    "\n",
    "    # 2. Normalize quotes\n",
    "    text = text.replace(\"``\", '\"').replace(\"''\", '\"')\n",
    "\n",
    "    # 3. Remove page/stat markers and generic brackets junk\n",
    "    text = re.sub(r\"\\[\\[.*?\\]\\]\", \" \", text)\n",
    "    text = re.sub(r\"\\[From the U\\.S\\. Government Publishing Office\\]\", \" \", text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r\"\\[\\s*\\d+th Congress Public Law[^\\]]*\\]\", \" \", text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r\"\\[\\s*Congressional Bills[^\\]]*\\]\", \" \", text, flags=re.IGNORECASE)\n",
    "\n",
    "    # 4. Remove NOTE-style artifacts like <<NOTE: ... >>\n",
    "    text = re.sub(r\"<<.*?>>\", \" \", text)\n",
    "\n",
    "    # 5. Drop procedural tail (LEGISLATIVE HISTORY and friends)\n",
    "    pattern_tail = r\"(\" + \"|\".join(tail_triggers) + r\")[\\s\\S]*$\"\n",
    "    text = re.sub(pattern_tail, \" \", text, flags=re.IGNORECASE)\n",
    "\n",
    "    # 6. Remove low-signal boilerplate phrases\n",
    "    for phrase in boilerplate_phrases:\n",
    "        text = re.sub(re.escape(phrase), \" \", text, flags=re.IGNORECASE)\n",
    "\n",
    "    # 7. Remove repeated words like \"sec sec\" (rare but safe)\n",
    "    text = re.sub(r\"\\b(\\w+)( \\1\\b)+\", r\"\\1\", text, flags=re.IGNORECASE)\n",
    "\n",
    "    # 8. Keep alphanumeric + basic punctuation; drop HTML/markup leftovers\n",
    "    text = re.sub(r\"[^A-Za-z0-9\\s\\.\\,\\;\\:\\?\\!\\-]\", \" \", text)\n",
    "\n",
    "    # 9. Normalize whitespace\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "\n",
    "    return text\n",
    "\n",
    "# Apply full pipeline to your dataset\n",
    "bills[\"clean_text\"] = (\n",
    "    bills[\"full_text\"]\n",
    "    .astype(str)\n",
    "    .apply(strip_html)\n",
    "    .apply(clean_bill_text)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6f2898a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Public Law 118-259 118th Congress To name the Department of Veterans Affairs community-based outpatient clinic in Auburn, California, as the Louis A. Conter VA Clinic . Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled, SECTION 1. FINDINGS. Congress finds the following: 1 Louis Lou Anthony Conter was born on September 13, 1921, in Ojibwa, Wisconsin. 2 Lt. Commander Lou Conter, the last remaining survivor of the attack on the USS Arizona at Pearl Harbor, was an American hero. 3 On that fearful day, Petty Officer Conter helped evacuate shipmates who were blinded, wounded, or burned, even restraining some of his fellow shipmates from jumping overboard into the burning sea. 4 In the days after the attack, he helped with recovering bodies and putting out fires. Lou Conter s heroic actions saved the lives of many of his shipmates on December 7, 1941. 5 Following Pearl Harbor, Conter continued serving during WWII in New Guinea and in Europe as an enlisted naval aviation pilot assigned to VP-11, a Black Cat Squadron. 6 Lou Conter would be awarded with the Distinguished Flying Cross for actively taking part in the rescue of 219 Australians trapped by Japanese troops in New Guinea. 7 Later, in the Korean War, he served on the USS Bon Homme Richard as both an intelligence officer and a navy aviation pilot. Following his service in the Korean War, he served as a military intelligence advisor to three Presidents: Dwight D. Eisenhower, John F. Kennedy, and Lyndon B. Johnson. 8 During the 1950s, Lou Conter played a prominent role in the establishment and development of the Navy Survival, Evasion, Resistance and Escape SERE training program. 9 In addition to the Distinguished Flying Cross, he was awarded the Navy Commendation Medal and became the first recipient of the USS Arizona Medal of Freedom. 10 Louis Conter retired from the Navy in 1967 after serving 28 years as a Lieutenant Commander. 11 Following his retirement, he generously gave his time to share his personal experiences at veterans ceremonies and by giving lectures to students. 12 Lieutenant Commander Conter s lectures were popular with generations of local students who were equally fascinated and enthralled by his first-person accounts. 13 He is eminently deserving of recognition for his decades of service to a grateful nation. 14 Lieutenant Commander Conter passed away in Grass Valley, California on April 1, 2024. SEC. 2. NAME OF DEPARTMENT OF VETERANS AFFAIRS COMMUNITY-BASED OUTPATIENT CLINIC, AUBURN, CALIFORNIA. The Department of Veterans Affairs community-based outpatient clinic in Auburn, California, shall after the date of the enactment of this Act be known and designated as the Louis A. Conter VA Clinic . Any reference to such clinic in any law, regulation, map, document, record, or other paper of the United States shall be considered to be a reference to the Louis A. Conter VA Clinic. Approved January 4, 2025.'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bills.iloc[0]['clean_text'][:10000]  # Display the first 10000 characters of the law text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf36c641",
   "metadata": {},
   "source": [
    "If you use sentence-transformers (MPNet, all-mpnet-base-v2, etc.) or Hugging Face tokenizers, no need to lowercase. Those tokenizers handle case internally and were trained on cased text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448ff690",
   "metadata": {},
   "source": [
    "## 3.1 Extract a shorter “front” text\n",
    "\n",
    "Full bills can be > 10k tokens; some models choke. Use a heuristic “front slice”. \n",
    "* Classic ML (tf-idf) can use full raw_text (within memory).\n",
    "* Transformers may use snippet_text or chunked raw_text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7ff7d2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def front_snippet(text, max_chars=5000):\n",
    "#     text = text[:max_chars]\n",
    "#     return text\n",
    "\n",
    "# bills[\"snippet_text\"] = bills[\"clean_text\"].apply(front_snippet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3cec34f",
   "metadata": {},
   "source": [
    "## 3.2 Document length features\n",
    "\n",
    "We can extract quantitative properties of the cleaned text. These tell us distribution of bill lengths. It matters because:\n",
    "\n",
    "* Extremely long bills\n",
    "\n",
    "* Very short “joint resolutions”\n",
    "\n",
    "* Text length correlates with probability of passage in some congresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "928422de",
   "metadata": {},
   "outputs": [],
   "source": [
    "bills[\"len_chars\"] = bills[\"clean_text\"].str.len()\n",
    "bills[\"len_words\"] = bills[\"clean_text\"].str.split().apply(len)\n",
    "bills[\"len_sentences\"] = bills[\"clean_text\"].str.count(r\"\\.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578df17c",
   "metadata": {},
   "source": [
    "## 3.3 Section headers extraction\n",
    "\n",
    "Many bills follow patterns:\n",
    "\n",
    "“Be it enacted…”\n",
    "\n",
    "“Section 1.”\n",
    "\n",
    "“Short Title”\n",
    "\n",
    "“Findings”\n",
    "\n",
    "“Definitions”\n",
    "\n",
    "Sometimes “real” legislation has more structural sections than symbolic resolutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "fb091e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "bills[\"section_count\"] = bills[\"clean_text\"].str.count(r\"SEC\\.|Section\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82312354",
   "metadata": {},
   "source": [
    "# 4. EDA: class balance, per congress\n",
    "\n",
    "Need to know how bad the imbalance is and how it varies over time.\n",
    "\n",
    "Insights we can expect:\n",
    "\n",
    "* Pass rate maybe around 5–20% depending on what exactly these `True` values represent.\n",
    "\n",
    "* Bills of type `HJRES` vs `HR` vs `S` may have different probabilities.\n",
    "\n",
    "* Extreme variation in length.\n",
    "\n",
    "* Maybe treat bill type & congress as features or even build type-specific models later.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3620c19b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13812 entries, 0 to 13811\n",
      "Data columns (total 17 columns):\n",
      " #   Column         Non-Null Count  Dtype         \n",
      "---  ------         --------------  -----         \n",
      " 0   id             13812 non-null  object        \n",
      " 1   date           13812 non-null  datetime64[ns]\n",
      " 2   law            13812 non-null  object        \n",
      " 3   full_text      13812 non-null  object        \n",
      " 4   congress       13812 non-null  int64         \n",
      " 5   bill_type      13812 non-null  object        \n",
      " 6   bill_number    13812 non-null  int64         \n",
      " 7   chamber        13812 non-null  object        \n",
      " 8   label          13812 non-null  int64         \n",
      " 9   year           13812 non-null  int32         \n",
      " 10  month          13812 non-null  int32         \n",
      " 11  day_of_year    13812 non-null  int32         \n",
      " 12  clean_text     13812 non-null  object        \n",
      " 13  len_chars      13812 non-null  int64         \n",
      " 14  len_words      13812 non-null  int64         \n",
      " 15  len_sentences  13812 non-null  int64         \n",
      " 16  section_count  13812 non-null  int64         \n",
      "dtypes: datetime64[ns](1), int32(3), int64(7), object(6)\n",
      "memory usage: 1.6+ MB\n"
     ]
    }
   ],
   "source": [
    "bills.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "566ec7b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many values for each label: \n",
      " label\n",
      "0    0.996742\n",
      "1    0.003258\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(f\"How many values for each label: \\n\", bills[\"label\"].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61fce89f",
   "metadata": {},
   "source": [
    "The 113th Congress ran from 2013 to 2014, while the 119th Congress is currently in session from 2025 to 2026. The years between these two Congresses are 2015-2016 (114th), 2017-2018 (115th), 2019-2020 (116th), and 2021-2024 (117th and 118th). Each numbered Congress serves a two-year term, starting with the 113th Congress in 2013. \n",
    "\n",
    "113th Congress: 2013–2014\n",
    "\n",
    "114th Congress: 2015–2016\n",
    "\n",
    "115th Congress: 2017–2018\n",
    "\n",
    "116th Congress: 2019–2020\n",
    "\n",
    "117th Congress: 2021–2022\n",
    "\n",
    "118th Congress: 2023–2024\n",
    "\n",
    "119th Congress: 2025–2026 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "acef9407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass Rate by Congress:\n",
      " congress\n",
      "113    0.028037\n",
      "114    0.010687\n",
      "115    0.016923\n",
      "116    0.000418\n",
      "117    0.003599\n",
      "118    0.001244\n",
      "119    0.000000\n",
      "Name: label, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(f\"Pass Rate by Congress:\\n\", bills.groupby(\"congress\")[\"label\"].mean())      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "96d9c812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass Rate by Type:\n",
      " bill_type\n",
      "HJRES    0.006192\n",
      "HR       0.001428\n",
      "S        0.008101\n",
      "SJRES    0.000000\n",
      "Name: label, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(f\"Pass Rate by Type:\\n\", bills.groupby(\"bill_type\")[\"label\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2667e53f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents Length Distribution:\n",
      " count    1.381200e+04\n",
      "mean     7.208960e+03\n",
      "std      2.793674e+04\n",
      "min      3.300000e+01\n",
      "25%      1.778750e+03\n",
      "50%      3.301000e+03\n",
      "75%      6.809000e+03\n",
      "max      1.785918e+06\n",
      "Name: clean_text, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(f\"Documents Length Distribution:\\n\", bills[\"clean_text\"].str.len().describe()) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e423e50",
   "metadata": {},
   "source": [
    "# 5. Train / validation / test splitting "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f33ca1",
   "metadata": {},
   "source": [
    "## 5.1 Time-based split\n",
    "\n",
    "We have congresses from 113 to 119 (2013–2025). We can use them like this:\n",
    "\n",
    "Train: 113–116 (older)\n",
    "\n",
    "Validation: 117\n",
    "\n",
    "Test: 118–119 (latest)\n",
    "\n",
    "This way model learns on history and is evaluated on near-future plus truly future congress.\n",
    "\n",
    "**NOTE:** We’re using a time-based split, not a random split. This means we never stratify, because stratification shuffles across time and leaks future information backward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "8361ca89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- TRAIN (<=116) ---\n",
      "Rows: 6516\n",
      "label\n",
      "0    6484\n",
      "1      32\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--- VAL (==117) ---\n",
      "Rows: 1667\n",
      "label\n",
      "0    1661\n",
      "1       6\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--- TEST (>=118) ---\n",
      "Rows: 5629\n",
      "label\n",
      "0    5622\n",
      "1       7\n",
      "Name: count, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check how many passing bills per time period\n",
    "def summarize(mask, name):\n",
    "    subset = bills[mask]\n",
    "    print(f\"--- {name} ---\")\n",
    "    print(\"Rows:\", len(subset))\n",
    "    print(subset[\"label\"].value_counts())\n",
    "    print()\n",
    "\n",
    "mask_train = bills[\"congress\"] <= 116\n",
    "mask_val   = bills[\"congress\"] == 117\n",
    "mask_test  = bills[\"congress\"] >= 118\n",
    "\n",
    "summarize(mask_train, \"TRAIN (<=116)\")\n",
    "summarize(mask_val,   \"VAL (==117)\")\n",
    "summarize(mask_test,  \"TEST (>=118)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f4281c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train, validation and test sets\n",
    "train_mask = bills[\"congress\"] <= 116\n",
    "val_mask   = bills[\"congress\"] == 117\n",
    "test_mask  = bills[\"congress\"] >= 118\n",
    " \n",
    "train_bills = bills[train_mask]\n",
    "val_bills   = bills[val_mask]\n",
    "test_bills  = bills[test_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "139fe44a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train rows: 6516\n",
      "Val rows:   1667\n",
      "Test rows:  5629\n"
     ]
    }
   ],
   "source": [
    "print(\"Train rows:\", train_mask.sum())\n",
    "print(\"Val rows:  \", val_mask.sum())\n",
    "print(\"Test rows: \", test_mask.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b51f0348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Targets\n",
    "y_train = train_bills[\"label\"].values\n",
    "y_val   = val_bills[\"label\"].values\n",
    "y_test  = test_bills[\"label\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2845c560",
   "metadata": {},
   "source": [
    "# 6. TF–IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0cfe637",
   "metadata": {},
   "source": [
    "## 6.1 Build a tf-idf vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "322695f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The vectorizer converts the long text documents into tf-idf features.\n",
    "\n",
    "tfidf = TfidfVectorizer(\n",
    "    ngram_range=(1, 2),     # unigrams + bigrams; captures basic structure\n",
    "    min_df=5,               # drop tokens that appear in fewer than 5 bills\n",
    "    max_df=0.9,             # drop tokens that appear in over 90% of bills\n",
    "    max_features=200000      # cap vocabulary size for memory stability\n",
    ")\n",
    "\n",
    "# Fit on training full text only. This builds the vocabulary.\n",
    "X_train_tfidf = tfidf.fit_transform(train_bills[\"clean_text\"])\n",
    "\n",
    "# Apply the same transformation to validation and test sets.\n",
    "X_val_tfidf  = tfidf.transform(val_bills[\"clean_text\"])\n",
    "X_test_tfidf = tfidf.transform(test_bills[\"clean_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6100ea8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base VAL  ROC-AUC: 0.5\n",
      "Base TEST ROC-AUC: 0.5\n",
      "Base TEST PR-AUC: 0.0012435601350151003\n",
      "Base TEST Precision: 0.0\n",
      "Base TEST Recall: 0.0\n",
      "Base TEST F1: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Baseline predictor\n",
    "# Mean pass rate in the TRAIN set\n",
    "base_rate = y_train.mean()\n",
    "\n",
    "# Predict constant probability for every sample\n",
    "p_train_base = np.full_like(y_train, fill_value=base_rate, dtype=float)\n",
    "p_val_base   = np.full_like(y_val,   fill_value=base_rate, dtype=float)\n",
    "p_test_base  = np.full_like(y_test,  fill_value=base_rate, dtype=float)\n",
    "\n",
    "# Convert probabilities into predicted labels using 0.5 threshold\n",
    "y_train_pred = (p_train_base >= 0.5).astype(int)\n",
    "y_val_pred   = (p_val_base   >= 0.5).astype(int)\n",
    "y_test_pred  = (p_test_base  >= 0.5).astype(int)\n",
    "\n",
    "# METRICS\n",
    "\n",
    "print(\"Base VAL  ROC-AUC:\",  roc_auc_score(y_val,  p_val_base))\n",
    "print(\"Base TEST ROC-AUC:\",  roc_auc_score(y_test, p_test_base))\n",
    "\n",
    "print(\"Base TEST PR-AUC:\",   average_precision_score(y_test, p_test_base))\n",
    "\n",
    "print(\"Base TEST Precision:\", precision_score(y_test, y_test_pred, zero_division=0))\n",
    "print(\"Base TEST Recall:\",    recall_score(y_test, y_test_pred, zero_division=0))\n",
    "print(\"Base TEST F1:\",        f1_score(y_test, y_test_pred, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976562e3",
   "metadata": {},
   "source": [
    "Baseline = “always predict the historical pass rate.” This is a dumb benchmark. AUC will be around 0.5; PR-AUC will be roughly the positive rate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07683fdd",
   "metadata": {},
   "source": [
    "## 6.2 Add simple numeric features\n",
    "\n",
    "We can later augment tf-idf with numeric columns like bill length or congress. For now, we're keeping it text-only for the first baseline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83456c36",
   "metadata": {},
   "source": [
    "## 6.3 Probability threshold tuning\n",
    "\n",
    "Each classifier outputs a probability p = P(law=True). With an imbalanced class, the default threshold of 0.5 is useless."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143c68ea",
   "metadata": {},
   "source": [
    "**Note:**\n",
    "\n",
    "The model gives a probability `p` that a bill will pass. We convert that probability into a final prediction (0 or 1) using a threshold. Usually we would use 0.5, but that makes no sense in an imbalanced problem.\n",
    "\n",
    "The positive class (“bill passes”) is rare. So `p` is usually small, even when the model believes the bill is likely to pass relative to the dataset.\n",
    "\n",
    "We fix this by choosing a threshold that maximizes a metric you care about. We do that on the validation set (never test).\n",
    "\n",
    "Mechanics:\n",
    "\n",
    "* Compute precision and recall at every possible cutoff.\n",
    "\n",
    "* Compute F1 score for each cutoff:\n",
    "\n",
    "* F1 = 2 * precision * recall / (precision + recall)\n",
    "\n",
    "Find which threshold gives the best F1 (or best recall, or best precision, depending on goals).\n",
    "\n",
    "Then you evaluate on the test set using that threshold: `y_test_pred = (p_test >= best_thresh).astype(int)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "6315dba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve, precision_score, recall_score, f1_score\n",
    "\n",
    "def pick_best_threshold_f1(y_true, p_scores):\n",
    "    \"\"\"\n",
    "    Given true labels and predicted probabilities on the VALIDATION set,\n",
    "    compute precision/recall at all thresholds and return the threshold\n",
    "    that maximizes F1.\n",
    "    \"\"\"\n",
    "    precision, recall, thresholds = precision_recall_curve(y_true, p_scores)\n",
    "\n",
    "    # last precision/recall point corresponds to threshold=+inf, ignore it\n",
    "    precision = precision[:-1]\n",
    "    recall = recall[:-1]\n",
    "    thresholds = thresholds\n",
    "\n",
    "    f1_scores = 2 * precision * recall / (precision + recall + 1e-8)\n",
    "    best_idx = f1_scores.argmax()\n",
    "    best_thresh = thresholds[best_idx]\n",
    "\n",
    "    print(\"Best threshold (by F1):\", best_thresh)\n",
    "    print(\"VAL precision at best thresh:\", precision[best_idx])\n",
    "    print(\"VAL recall at best thresh:   \", recall[best_idx])\n",
    "    print(\"VAL F1 at best thresh:       \", f1_scores[best_idx])\n",
    "\n",
    "    return best_thresh\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15159b2c",
   "metadata": {},
   "source": [
    "# 7. Baseline models on TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b2e7ce",
   "metadata": {},
   "source": [
    "## 7.1 Logistic regression + TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4238ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold (by F1): 0.29299534786519704\n",
      "VAL precision at best thresh: 0.5714285714285714\n",
      "VAL recall at best thresh:    0.6666666666666666\n",
      "VAL F1 at best thresh:        0.6153846104142012\n",
      "LogReg TEST precision: 0.14705882352941177\n",
      "LogReg TEST recall:    0.7142857142857143\n",
      "LogReg TEST F1:        0.24390243902439024\n",
      "LogReg VAL AUC: 0.9969897652016858\n",
      "LogReg TEST AUC: 0.9763937592112619\n",
      "LogReg TEST PR-AUC: 0.4167401435086253\n"
     ]
    }
   ],
   "source": [
    "# Linear classifier for high-dimensional sparse TF-IDF.\n",
    "# Balanced weights counter the strong imbalance (few bills pass).\n",
    "logreg = LogisticRegression(\n",
    "    max_iter=2000,\n",
    "    n_jobs=-1,\n",
    "    class_weight=\"balanced\"\n",
    ")\n",
    "\n",
    "# Train only on past congresses.\n",
    "logreg.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Probability of passage for validation and test sets.\n",
    "p_val_lr  = logreg.predict_proba(X_val_tfidf)[:, 1]\n",
    "p_test_lr = logreg.predict_proba(X_test_tfidf)[:, 1]\n",
    "\n",
    "# Pick threshold on VALIDATION set\n",
    "best_thresh_lr = pick_best_threshold_f1(y_val, p_val_lr)\n",
    "\n",
    "# Turn probabilities into class predictions using best threshold.\n",
    "y_val_pred_lr  = (p_val_lr  >= best_thresh_lr).astype(int)\n",
    "y_test_pred_lr = (p_test_lr >= best_thresh_lr).astype(int)\n",
    "\n",
    "# METRICS \n",
    "\n",
    "print(\"LogReg TEST precision:\", precision_score(y_test, y_test_pred_lr))\n",
    "print(\"LogReg TEST recall:   \", recall_score(y_test,  y_test_pred_lr))\n",
    "print(\"LogReg TEST F1:       \", f1_score(y_test,     y_test_pred_lr))\n",
    "\n",
    "# Ranking metrics (threshold-free); AUC and PR-AUC ignore the threshold\n",
    "print(\"LogReg VAL AUC:\",      roc_auc_score(y_val,  p_val_lr))\n",
    "print(\"LogReg TEST AUC:\",     roc_auc_score(y_test, p_test_lr))\n",
    "print(\"LogReg TEST PR-AUC:\",  average_precision_score(y_test, p_test_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0427d314",
   "metadata": {},
   "source": [
    "TEST ROC-AUC: 0.976\n",
    "\n",
    "TEST PR-AUC: 0.417\n",
    "\n",
    "Precision: 0.15\n",
    "\n",
    "Recall: 0.71\n",
    "\n",
    "F1: 0.24\n",
    "\n",
    "Meaning:\n",
    "\n",
    "Correctly catch ~70% of the true passing bills. But every 1 correct “pass” prediction comes with about 6 false alarms.\n",
    "\n",
    "Ranking quality is strong; classification isn't good."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ecad7d",
   "metadata": {},
   "source": [
    "## 7.2 Linear SVM + tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "7d83bd5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold (by F1): 0.0395114882929851\n",
      "VAL precision at best thresh: 0.5454545454545454\n",
      "VAL recall at best thresh:    1.0\n",
      "VAL F1 at best thresh:        0.7058823483737025\n",
      "SVM TEST precision: 0.14705882352941177\n",
      "SVM TEST recall:    0.7142857142857143\n",
      "SVM TEST F1:        0.24390243902439024\n",
      "SVM VAL AUC: 0.9984948826008428\n",
      "SVM TEST AUC: 0.9859226508105909\n",
      "SVM TEST PR-AUC: 0.5393499331478957\n"
     ]
    }
   ],
   "source": [
    "# Linear SVM with class balancing.\n",
    "svm = LinearSVC(class_weight=\"balanced\")\n",
    "\n",
    "# SVM does not output probabilities.\n",
    "# CalibratedClassifierCV wraps it and learns a sigmoid to produce calibrated probabilities.\n",
    "svm_cal = CalibratedClassifierCV(svm, method=\"sigmoid\", cv=5)\n",
    "\n",
    "# Fit on training full-text TF-IDF.\n",
    "svm_cal.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Probability outputs for validation and test.\n",
    "p_val_svm  = svm_cal.predict_proba(X_val_tfidf)[:, 1]\n",
    "p_test_svm = svm_cal.predict_proba(X_test_tfidf)[:, 1]\n",
    "\n",
    "# Pick threshold on VALIDATION set.\n",
    "best_thresh_svm = pick_best_threshold_f1(y_val, p_val_svm)\n",
    "\n",
    "# Turn probabilities into class predictions using best threshold.\n",
    "y_val_pred_svm  = (p_val_svm  >= best_thresh_svm).astype(int)\n",
    "y_test_pred_svm = (p_test_svm >= best_thresh_svm).astype(int)\n",
    "\n",
    "# METRICS \n",
    "\n",
    "# Thresholded point metrics on TEST at best_thresh_svm.\n",
    "print(\"SVM TEST precision:\", precision_score(y_test, y_test_pred_svm, zero_division=0))\n",
    "print(\"SVM TEST recall:   \", recall_score(y_test,  y_test_pred_svm, zero_division=0))\n",
    "print(\"SVM TEST F1:       \", f1_score(y_test,     y_test_pred_svm, zero_division=0))\n",
    "\n",
    "# Ranking metrics (threshold-free); AUC and PR-AUC ignore the threshold.\n",
    "print(\"SVM VAL AUC:\",      roc_auc_score(y_val,  p_val_svm))\n",
    "print(\"SVM TEST AUC:\",     roc_auc_score(y_test, p_test_svm))\n",
    "print(\"SVM TEST PR-AUC:\",  average_precision_score(y_test, p_test_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f1a7d8",
   "metadata": {},
   "source": [
    "Metrics almost identical to LR.\n",
    "\n",
    "PR-AUC improves to 0.54.\n",
    "\n",
    "Meaning: \n",
    "\n",
    "Same trade-off: high recall, awful precision. Still far from reliable yes/no predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd596f9",
   "metadata": {},
   "source": [
    "## 7.3 XGBoost + TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "4b3b5945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold (by F1): 0.9944706\n",
      "VAL precision at best thresh: 1.0\n",
      "VAL recall at best thresh:    1.0\n",
      "VAL F1 at best thresh:        0.999999995\n",
      "XGB TEST precision: 1.0\n",
      "XGB TEST recall:    0.8571428571428571\n",
      "XGB TEST F1:        0.9230769230769231\n",
      "XGB VAL ROC-AUC: 1.0\n",
      "XGB TEST ROC-AUC: 1.0\n",
      "XGB TEST PR-AUC: 0.9999999999999998\n"
     ]
    }
   ],
   "source": [
    "# 1) Class imbalance: compute scale_pos_weight = N_neg / N_pos from TRAIN only.\n",
    "n_pos = np.sum(y_train == 1)\n",
    "n_neg = np.sum(y_train == 0)\n",
    "scale_pos = n_neg / n_pos\n",
    "\n",
    "# XGBoost on TF-IDF features\n",
    "xgb = XGBClassifier(\n",
    "    objective=\"binary:logistic\", # outputs probability bill passes\n",
    "    eval_metric=\"logloss\",\n",
    "    n_estimators=500,\n",
    "    learning_rate=0.01, # low learning_rate, shallow max_depth → more stable, less overfit\n",
    "    max_depth=4,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    scale_pos_weight=scale_pos, # makes rare \"pass\" class matter\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit on past congresses only.\n",
    "xgb.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predict probabilities of passage for VAL and TEST.\n",
    "p_val_xgb  = xgb.predict_proba(X_val_tfidf)[:, 1]\n",
    "p_test_xgb = xgb.predict_proba(X_test_tfidf)[:, 1]\n",
    "\n",
    "# Pick threshold on VALIDATION set \n",
    "best_thresh_xgb = pick_best_threshold_f1(y_val, p_val_xgb)\n",
    "\n",
    "# Convert probabilities into hard labels at best_thresh_xgb.\n",
    "y_val_pred_xgb  = (p_val_xgb  >= best_thresh_xgb).astype(int)\n",
    "y_test_pred_xgb = (p_test_xgb >= best_thresh_xgb).astype(int)\n",
    "\n",
    "# METRICS \n",
    "print(\"XGB TEST precision:\", precision_score(y_test, y_test_pred_xgb, zero_division=0))\n",
    "print(\"XGB TEST recall:   \", recall_score(y_test,  y_test_pred_xgb, zero_division=0))\n",
    "print(\"XGB TEST F1:       \", f1_score(y_test,     y_test_pred_xgb, zero_division=0))\n",
    "\n",
    "print(\"XGB VAL ROC-AUC:\",      roc_auc_score(y_val,  p_val_xgb))\n",
    "print(\"XGB TEST ROC-AUC:\",     roc_auc_score(y_test, p_test_xgb))\n",
    "print(\"XGB TEST PR-AUC:\",      average_precision_score(y_test, p_test_xgb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac7fca9",
   "metadata": {},
   "source": [
    "**Raw TF-IDF + XGB:**\n",
    "\n",
    "VAL & TEST ROC-AUC: 1.00\n",
    "\n",
    "TEST PR-AUC: ~1.00\n",
    "\n",
    "Precision: 1.00\n",
    "\n",
    "Recall: 0.86\n",
    "\n",
    "F1: 0.92\n",
    "\n",
    "**TF-IDF + Metadata + XGB:** Same near-perfect numbers.\n",
    "\n",
    "This is statistically implausible and almost certainly indicates data leakage or target contamination. Real-world legislative prediction does not produce perfect classification from pure language alone.\n",
    "\n",
    "**Why this happened:**\n",
    "\n",
    "Passed bills contain:\n",
    "\n",
    "“Public Law ###”\n",
    "\n",
    "“Approved January …”\n",
    "\n",
    "“considered and passed House / Senate”\n",
    "\n",
    "Those phrases directly encode the label. The cleaned text contains post-vote signals. So the model isn’t predicting success from bill content. It’s simply detecting the bill already became law.\n",
    "\n",
    "**The issues is** that our model is not a model of prediction, but a model of document state recognition. Completely invalid for forecasting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7355ca02",
   "metadata": {},
   "source": [
    "# 8. Add simple structured features to TF-IDF\n",
    "\n",
    "TF-IDF encodes text; numeric + one-hot features encode structural context (congress, chamber, bill type, length, etc.). Models now see both language and structural signals.\n",
    "\n",
    "Create numeric matrix of these:\n",
    "\n",
    "`congress`\n",
    "\n",
    "`bill_type`\n",
    "\n",
    "`chamber`\n",
    "\n",
    "`year, month, etc.`\n",
    "\n",
    "and combine with tf-idf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65790fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Build metadata matrices \n",
    "\n",
    "# Numeric metadata columns already exist in `bills`\n",
    "num_cols = [\"congress\", \"year\", \"month\", \"len_words\", \"section_count\"]\n",
    "\n",
    "X_train_num = train_bills[num_cols].to_numpy()\n",
    "X_val_num   = val_bills[num_cols].to_numpy()\n",
    "X_test_num  = test_bills[num_cols].to_numpy()\n",
    "\n",
    "# Categorical metadata\n",
    "cat_cols = [\"bill_type\", \"chamber\"]\n",
    "\n",
    "enc = OneHotEncoder(handle_unknown=\"ignore\") # sparse=True default\n",
    "\n",
    "X_train_cat = enc.fit_transform(train_bills[cat_cols])\n",
    "X_val_cat   = enc.transform(val_bills[cat_cols])\n",
    "X_test_cat  = enc.transform(test_bills[cat_cols])\n",
    "\n",
    "# Combine TF-IDF + numeric + categorical\n",
    "X_train_meta = hstack([X_train_tfidf, X_train_num, X_train_cat])\n",
    "X_val_meta   = hstack([X_val_tfidf,   X_val_num,   X_val_cat])\n",
    "X_test_meta  = hstack([X_test_tfidf,  X_test_num,  X_test_cat])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9bd392",
   "metadata": {},
   "source": [
    "## 8.1 Logistic Regression + metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "723221e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold (by F1): 0.6456334378706323\n",
      "VAL precision at best thresh: 1.0\n",
      "VAL recall at best thresh:    0.3333333333333333\n",
      "VAL F1 at best thresh:        0.4999999962500001\n",
      "LogReg+Meta TEST precision: 0.0\n",
      "LogReg+Meta TEST recall:    0.0\n",
      "LogReg+Meta TEST F1:        0.0\n",
      "LogReg+Meta VAL AUC: 0.9960866947621915\n",
      "LogReg+Meta TEST AUC: 0.9880571225288408\n",
      "LogReg+Meta TEST PR-AUC: 0.36126111886760975\n"
     ]
    }
   ],
   "source": [
    "logreg_meta = LogisticRegression(\n",
    "    max_iter=2000,\n",
    "    n_jobs=-1,\n",
    "    class_weight=\"balanced\"  # imbalanced data\n",
    ")\n",
    "\n",
    "# Fit on combined features from past congresses\n",
    "logreg_meta.fit(X_train_meta, y_train)\n",
    "\n",
    "# Predict probabilities bill passes on val/test\n",
    "p_val_lr_meta  = logreg_meta.predict_proba(X_val_meta)[:, 1]\n",
    "p_test_lr_meta = logreg_meta.predict_proba(X_test_meta)[:, 1]\n",
    "\n",
    "# Pick threshold on VALIDATION set (model-specific).\n",
    "best_thresh_lr_meta = pick_best_threshold_f1(y_val, p_val_lr_meta)\n",
    "\n",
    "# Convert probabilities into class predictions using best threshold.\n",
    "y_val_pred_meta  = (p_val_lr_meta  >= best_thresh_lr_meta).astype(int)\n",
    "y_test_pred_meta = (p_test_lr_meta >= best_thresh_lr_meta).astype(int)\n",
    "\n",
    "# METRICS\n",
    "# Thresholded metrics on TEST\n",
    "print(\"LogReg+Meta TEST precision:\", precision_score(y_test, y_test_pred_meta, zero_division=0))\n",
    "print(\"LogReg+Meta TEST recall:   \", recall_score(y_test,  y_test_pred_meta, zero_division=0))\n",
    "print(\"LogReg+Meta TEST F1:       \", f1_score(y_test,     y_test_pred_meta, zero_division=0))\n",
    "\n",
    "# Ranking metrics that ignore threshold\n",
    "print(\"LogReg+Meta VAL AUC:\",      roc_auc_score(y_val,  p_val_lr_meta))\n",
    "print(\"LogReg+Meta TEST AUC:\",     roc_auc_score(y_test, p_test_lr_meta))\n",
    "print(\"LogReg+Meta TEST PR-AUC:\",  average_precision_score(y_test, p_test_lr_meta))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a534d87",
   "metadata": {},
   "source": [
    "## 8.2 Calibrated Linear SVM + metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "f117e24e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\saram\\anaconda3\\envs\\erdos_fall_2024\\Lib\\site-packages\\sklearn\\svm\\_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\saram\\anaconda3\\envs\\erdos_fall_2024\\Lib\\site-packages\\sklearn\\svm\\_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\saram\\anaconda3\\envs\\erdos_fall_2024\\Lib\\site-packages\\sklearn\\svm\\_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\saram\\anaconda3\\envs\\erdos_fall_2024\\Lib\\site-packages\\sklearn\\svm\\_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\saram\\anaconda3\\envs\\erdos_fall_2024\\Lib\\site-packages\\sklearn\\svm\\_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold (by F1): 0.0057071349063341804\n",
      "VAL precision at best thresh: 0.03333333333333333\n",
      "VAL recall at best thresh:    0.5\n",
      "VAL F1 at best thresh:        0.062499998828125014\n",
      "SVM+Meta TEST precision: 0.03125\n",
      "SVM+Meta TEST recall:    0.14285714285714285\n",
      "SVM+Meta TEST F1:        0.05128205128205128\n",
      "SVM+Meta VAL ROC-AUC: 0.8321292394140076\n",
      "SVM+Meta TEST ROC-AUC: 0.8065253849672206\n",
      "SVM+Meta TEST PR-AUC: 0.0165619836556158\n"
     ]
    }
   ],
   "source": [
    "svm = LinearSVC(class_weight=\"balanced\")  # margin-based classifier\n",
    "svm_cal_meta = CalibratedClassifierCV(svm, method=\"sigmoid\", cv=5)\n",
    "# Calibration turns SVM scores into probabilities.\n",
    "\n",
    "# Fit on combined features\n",
    "svm_cal_meta.fit(X_train_meta, y_train)\n",
    "\n",
    "# Predict calibrated probabilities\n",
    "p_val_svm_meta  = svm_cal_meta.predict_proba(X_val_meta)[:, 1]\n",
    "p_test_svm_meta = svm_cal_meta.predict_proba(X_test_meta)[:, 1]\n",
    "\n",
    "# Choose the best threshold on VALIDATION set using F1.\n",
    "best_thresh_svm_meta = pick_best_threshold_f1(y_val, p_val_svm_meta)\n",
    "\n",
    "# Turn probabilities into class labels using the tuned threshold.\n",
    "y_val_pred_meta  = (p_val_svm_meta  >= best_thresh_svm_meta).astype(int)\n",
    "y_test_pred_meta = (p_test_svm_meta >= best_thresh_svm_meta).astype(int)\n",
    "\n",
    "# METRICS \n",
    "\n",
    "# Thresholded metrics on TEST (actual classification behavior).\n",
    "print(\"SVM+Meta TEST precision:\", precision_score(y_test, y_test_pred_meta, zero_division=0))\n",
    "print(\"SVM+Meta TEST recall:   \", recall_score(y_test,  y_test_pred_meta, zero_division=0))\n",
    "print(\"SVM+Meta TEST F1:       \", f1_score(y_test,     y_test_pred_meta, zero_division=0))\n",
    "\n",
    "# Ranking metrics (threshold-free).\n",
    "print(\"SVM+Meta VAL ROC-AUC:\",   roc_auc_score(y_val,  p_val_svm_meta))\n",
    "print(\"SVM+Meta TEST ROC-AUC:\",  roc_auc_score(y_test, p_test_svm_meta))\n",
    "print(\"SVM+Meta TEST PR-AUC:\",   average_precision_score(y_test, p_test_svm_meta))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78bd6025",
   "metadata": {},
   "source": [
    "## 8.3 XGBoost + metadata (with scale_pos_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "132faee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold (by F1): 0.9947003\n",
      "VAL precision at best thresh: 1.0\n",
      "VAL recall at best thresh:    1.0\n",
      "VAL F1 at best thresh:        0.999999995\n",
      "XGB+Meta TEST Precision: 1.0\n",
      "XGB+Meta TEST Recall: 0.8571428571428571\n",
      "XGB+Meta TEST F1: 0.9230769230769231\n",
      "XGB+Meta VAL ROC-AUC: 1.0\n",
      "XGB+Meta TEST ROC-AUC: 1.0\n",
      "XGB+Meta TEST PR-AUC: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Class imbalance: compute scale_pos_weight = N_neg / N_pos on TRAIN\n",
    "n_pos = np.sum(y_train == 1)\n",
    "n_neg = np.sum(y_train == 0)\n",
    "scale_pos = n_neg / n_pos\n",
    "\n",
    "xgb_meta = XGBClassifier(\n",
    "    objective=\"binary:logistic\",\n",
    "    eval_metric=\"logloss\",\n",
    "    n_estimators=500,\n",
    "    learning_rate=0.01,  # low LR, more stable\n",
    "    max_depth=4,         # shallow trees on high-dim sparse\n",
    "    subsample=0.8,       # row subsampling\n",
    "    colsample_bytree=0.8, # feature subsampling\n",
    "    scale_pos_weight=scale_pos,  # corrects extreme imbalance\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit on combined features\n",
    "xgb_meta.fit(X_train_meta, y_train)\n",
    "\n",
    "# Predict probabilities of passage\n",
    "p_val_xgb_meta  = xgb_meta.predict_proba(X_val_meta)[:, 1]\n",
    "p_test_xgb_meta = xgb_meta.predict_proba(X_test_meta)[:, 1]\n",
    "\n",
    "# Pick best threshold on VALIDATION using F1\n",
    "best_thresh_xgb_meta = pick_best_threshold_f1(y_val, p_val_xgb_meta)\n",
    "\n",
    "# Turn probabilities into class labels using tuned threshold\n",
    "y_val_pred_xgb_meta  = (p_val_xgb_meta  >= best_thresh_xgb_meta).astype(int)\n",
    "y_test_pred_xgb_meta = (p_test_xgb_meta >= best_thresh_xgb_meta).astype(int)\n",
    "\n",
    "# METRICS \n",
    "# Thresholded metrics on TEST: how the classifier behaves in practice\n",
    "print(\"XGB+Meta TEST Precision:\", precision_score(y_test, y_test_pred_xgb_meta, zero_division=0))\n",
    "print(\"XGB+Meta TEST Recall:\",    recall_score(y_test,  y_test_pred_xgb_meta, zero_division=0))\n",
    "print(\"XGB+Meta TEST F1:\",        f1_score(y_test,     y_test_pred_xgb_meta, zero_division=0))\n",
    "\n",
    "# Threshold-free ranking metrics (use probabilities)\n",
    "print(\"XGB+Meta VAL ROC-AUC:\",   roc_auc_score(y_val,  p_val_xgb_meta))\n",
    "print(\"XGB+Meta TEST ROC-AUC:\",  roc_auc_score(y_test, p_test_xgb_meta))\n",
    "print(\"XGB+Meta TEST PR-AUC:\",   average_precision_score(y_test, p_test_xgb_meta))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3aee643",
   "metadata": {},
   "source": [
    "**Metadata hurt the linear models**\n",
    "\n",
    "Logistic + metadata:\n",
    "\n",
    "* High AUC\n",
    "\n",
    "* Zero precision / recall at tuned threshold\n",
    "\n",
    "Reason: Metadata (year, congress, length) creates extreme separation artifacts with so few positives.\n",
    "\n",
    "Threshold optimization on 6 validation positives overfits instantly.\n",
    "\n",
    "The validation set is too small for stable threshold tuning, so optimization becomes noise-fitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd448798",
   "metadata": {},
   "source": [
    "# 9. Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9c0d18",
   "metadata": {},
   "source": [
    "## 9.1 DistilBERT Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1f205df4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b55702d45a474e93acb3fb755a49d394",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/864 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# DistilBERT sentence-transformer model\n",
    "distil_model = SentenceTransformer(\"distilbert-base-nli-mean-tokens\")\n",
    "\n",
    "# Encode full cleaned bill text into dense vectors (one per bill)\n",
    "distil_emb = distil_model.encode(\n",
    "    bills[\"clean_text\"].tolist(),\n",
    "    batch_size=16,\n",
    "    show_progress_bar=True\n",
    ")\n",
    "distil_emb = np.array(distil_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "350945a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split embeddings into train/val/test using same masks\n",
    "X_train_distil = distil_emb[train_mask.values]\n",
    "X_val_distil   = distil_emb[val_mask.values]\n",
    "X_test_distil  = distil_emb[test_mask.values]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93732c0",
   "metadata": {},
   "source": [
    "## 9.2 Logistic Regression on DistilBERT Embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "baa4c140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold (by F1): 0.9955002922986003\n",
      "VAL precision at best thresh: 1.0\n",
      "VAL recall at best thresh:    0.8333333333333334\n",
      "VAL F1 at best thresh:        0.9090909041322315\n",
      "DistilBERT+LogReg TEST Precision: 1.0\n",
      "DistilBERT+LogReg TEST Recall: 0.5714285714285714\n",
      "DistilBERT+LogReg TEST F1: 0.7272727272727273\n",
      "DistilBERT+LogReg VAL ROC-AUC: 0.9997993176801123\n",
      "DistilBERT+LogReg TEST ROC-AUC: 0.9999237688672054\n",
      "DistilBERT+LogReg TEST PR-AUC: 0.947845804988662\n"
     ]
    }
   ],
   "source": [
    "logreg_distil = LogisticRegression(\n",
    "    max_iter=2000,\n",
    "    n_jobs=-1,\n",
    "    class_weight=\"balanced\"  \n",
    ")\n",
    "\n",
    "# Fit on past congresses' embedding vectors\n",
    "logreg_distil.fit(X_train_distil, y_train)\n",
    "\n",
    "# Predict probability bill will pass (class 1) on val/test\n",
    "p_val_lr_distil  = logreg_distil.predict_proba(X_val_distil)[:, 1]\n",
    "p_test_lr_distil = logreg_distil.predict_proba(X_test_distil)[:, 1]\n",
    "\n",
    "# Pick best threshold on VALIDATION using F1\n",
    "best_thresh_distil = pick_best_threshold_f1(y_val, p_val_lr_distil)\n",
    "\n",
    "# Turn probabilities into hard labels using tuned threshold\n",
    "y_val_pred_distil  = (p_val_lr_distil  >= best_thresh_distil).astype(int)\n",
    "y_test_pred_distil = (p_test_lr_distil >= best_thresh_distil).astype(int)\n",
    "\n",
    "# Thresholded metrics: how the classifier behaves in practice on TEST\n",
    "print(\"DistilBERT+LogReg TEST Precision:\",\n",
    "      precision_score(y_test, y_test_pred_distil, zero_division=0))\n",
    "print(\"DistilBERT+LogReg TEST Recall:\",\n",
    "      recall_score(y_test, y_test_pred_distil, zero_division=0))\n",
    "print(\"DistilBERT+LogReg TEST F1:\",\n",
    "      f1_score(y_test, y_test_pred_distil, zero_division=0))\n",
    "\n",
    "# Threshold-free ranking metrics (probability-based)\n",
    "print(\"DistilBERT+LogReg VAL ROC-AUC:\",\n",
    "      roc_auc_score(y_val, p_val_lr_distil))\n",
    "print(\"DistilBERT+LogReg TEST ROC-AUC:\",\n",
    "      roc_auc_score(y_test, p_test_lr_distil))\n",
    "print(\"DistilBERT+LogReg TEST PR-AUC:\",\n",
    "      average_precision_score(y_test, p_test_lr_distil))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72cdd81e",
   "metadata": {},
   "source": [
    "## 9.2 MPNet Embeddings\n",
    "Use pretrained transformer models to turn each bill’s text into a numerical vector.\n",
    "MPNet (sentence-transformers/all-mpnet-base-v2) tends to outperform BERT on semantic similarity and downstream classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b643872d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('all-mpnet-base-v2')\n",
    "\n",
    "# Encode bill text\n",
    "embeddings = model.encode(bills[\"clean_text\"].tolist(), \n",
    "                          batch_size=16, \n",
    "                          show_progress_bar=True)\n",
    "bills_emb = np.array(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "c95048ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# p = r\"C:/Users/saram/Desktop/Erdos_Institute/project-2025/\"\n",
    "\n",
    "# # Save\n",
    "# np.save(p + \"bill_embeddings.npy\", bills_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e838424b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load later\n",
    "bills_emb = np.load(p + \"bill_embeddings.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "fb4d81b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13812, 768)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bills_emb.shape  # Should be (num_bills, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "ce7aa5f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.0077152 ,  0.08115873, -0.00354219, ..., -0.00809604,\n",
       "         0.0123047 , -0.01125902],\n",
       "       [ 0.00645859,  0.01635592,  0.0276007 , ..., -0.02757508,\n",
       "        -0.03304846, -0.02868639],\n",
       "       [ 0.02797876,  0.03059493,  0.04683481, ..., -0.01529225,\n",
       "        -0.04337279, -0.01323536],\n",
       "       ...,\n",
       "       [ 0.03796244, -0.04223369,  0.03787776, ...,  0.0033854 ,\n",
       "        -0.00608084, -0.00959797],\n",
       "       [-0.06522495,  0.03699569,  0.00618374, ..., -0.02298611,\n",
       "        -0.0113249 ,  0.01463324],\n",
       "       [ 0.02661327, -0.00600304,  0.0545648 , ...,  0.03010296,\n",
       "        -0.03346274,  0.01599839]], shape=(13812, 768), dtype=float32)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bills_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "11786abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train/val/test\n",
    "X_train_mpnet = bills_emb[train_mask.values]\n",
    "X_val_mpnet   = bills_emb[val_mask.values]\n",
    "X_test_mpnet  = bills_emb[test_mask.values]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ed79ae",
   "metadata": {},
   "source": [
    "## 9.4 XGBoost on MPNet Embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "3fc6852c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold (by F1): 0.457284\n",
      "VAL precision at best thresh: 0.8333333333333334\n",
      "VAL recall at best thresh:    0.8333333333333334\n",
      "VAL F1 at best thresh:        0.8333333283333335\n",
      "MPNet+XGB TEST Precision: 0.8333333333333334\n",
      "MPNet+XGB TEST Recall: 0.7142857142857143\n",
      "MPNet+XGB TEST F1: 0.7692307692307693\n",
      "MPNet+XGB VAL ROC-AUC: 0.9904675898053381\n",
      "MPNet+XGB TEST ROC-AUC: 0.9986278396096966\n",
      "MPNet+XGB TEST PR-AUC: 0.7358843537414966\n"
     ]
    }
   ],
   "source": [
    "# Class imbalance: scale_pos_weight = N_neg / N_pos on TRAIN\n",
    "n_pos = np.sum(y_train == 1)\n",
    "n_neg = np.sum(y_train == 0)\n",
    "scale_pos = n_neg / n_pos\n",
    "\n",
    "xgb_mpnet = XGBClassifier(\n",
    "    objective=\"binary:logistic\",\n",
    "    eval_metric=\"logloss\",\n",
    "    n_estimators=500,     # enough trees with low LR\n",
    "    learning_rate=0.01,   # low learning rate for stability\n",
    "    max_depth=4,          # shallow trees to avoid overfitting\n",
    "    subsample=0.8,        # row subsampling\n",
    "    colsample_bytree=0.8, # feature subsampling\n",
    "    scale_pos_weight=scale_pos,  # fix extreme imbalance\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit boosted trees on MPNet embedding features\n",
    "xgb_mpnet.fit(X_train_mpnet, y_train)\n",
    "\n",
    "# Predict probability bill will pass\n",
    "p_val_xgb_mpnet  = xgb_mpnet.predict_proba(X_val_mpnet)[:, 1]\n",
    "p_test_xgb_mpnet = xgb_mpnet.predict_proba(X_test_mpnet)[:, 1]\n",
    "\n",
    "# Pick best threshold on VALIDATION set using F1\n",
    "best_thresh_xgb_mpnet = pick_best_threshold_f1(y_val, p_val_xgb_mpnet)\n",
    "\n",
    "# Hard predictions using tuned threshold\n",
    "y_val_pred_xgb_mpnet  = (p_val_xgb_mpnet  >= best_thresh_xgb_mpnet).astype(int)\n",
    "y_test_pred_xgb_mpnet = (p_test_xgb_mpnet >= best_thresh_xgb_mpnet).astype(int)\n",
    "\n",
    "# METRICS\n",
    "\n",
    "# Thresholded point metrics on TEST\n",
    "print(\"MPNet+XGB TEST Precision:\",\n",
    "      precision_score(y_test, y_test_pred_xgb_mpnet, zero_division=0))\n",
    "print(\"MPNet+XGB TEST Recall:\",\n",
    "      recall_score(y_test,  y_test_pred_xgb_mpnet, zero_division=0))\n",
    "print(\"MPNet+XGB TEST F1:\",\n",
    "      f1_score(y_test,     y_test_pred_xgb_mpnet, zero_division=0))\n",
    "\n",
    "# Threshold-free ranking metrics\n",
    "print(\"MPNet+XGB VAL ROC-AUC:\",\n",
    "      roc_auc_score(y_val, p_val_xgb_mpnet))\n",
    "print(\"MPNet+XGB TEST ROC-AUC:\",\n",
    "      roc_auc_score(y_test, p_test_xgb_mpnet))\n",
    "print(\"MPNet+XGB TEST PR-AUC:\",\n",
    "      average_precision_score(y_test, p_test_xgb_mpnet))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68b8797",
   "metadata": {},
   "source": [
    "# 10. Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9305226",
   "metadata": {},
   "source": [
    "**DistilBERT + Logistic Regression:**\n",
    "\n",
    "TEST PR-AUC: 0.95\n",
    "\n",
    "Precision: 1.00\n",
    "\n",
    "Recall: 0.57\n",
    "\n",
    "F1: 0.73\n",
    "\n",
    "**MPNet + XGBoost:**\n",
    "\n",
    "TEST PR-AUC: 0.74\n",
    "\n",
    "Precision: 0.83\n",
    "\n",
    "Recall: 0.71\n",
    "\n",
    "F1: 0.77\n",
    "\n",
    "**Interpretation:**\n",
    "Transformers perform extremely well but less perfectly than TF-IDF+XGB, which supports the leakage hypothesis.\n",
    "\n",
    "Transformers embed broader semantic content which dilutes the exact leakage tokens.\n",
    "\n",
    "TF-IDF + trees is acting like a keyword detector over “Public Law”, “Approved”, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4072bc",
   "metadata": {},
   "source": [
    "Overall, what each metric tells us\n",
    "\n",
    "* ROC-AUC:\tAlmost meaningless once it's >0.95 with heavy imbalance.\n",
    "* PR-AUC:\tThe only trustworthy ranking metric.\n",
    "* Precision:\tHow many flags you can trust. Currently bad except for leakage models.\n",
    "* Recall:\tAbility to find most winners. Linear methods and MPNet are decent here.\n",
    "* F1:\tOverall classification usefulness. Transformer > linear methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ff8b34",
   "metadata": {},
   "source": [
    "Best performing models (Ordered by true predictive quality)\n",
    "\n",
    "MPNet + XGBoost:\n",
    "Best balanced precision/recall without blatant leakage.\n",
    "\n",
    "DistilBERT + LogReg:\n",
    "Higher precision, lower recall.\n",
    "\n",
    "Linear SVM / LogReg on TF-IDF:\n",
    "Acceptable baseline; too many false positives.\n",
    "\n",
    "XGB with raw TF-IDF:\n",
    "Invalid due to leakage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42062abc",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erdos_fall_2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
