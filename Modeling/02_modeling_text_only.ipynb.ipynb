{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c8a863a",
   "metadata": {},
   "source": [
    "# NOTEBOOK 02: Will the Bill Make It Through Capitol Hill?\n",
    "Section 5–9: Text-Only Modeling & Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd6e063",
   "metadata": {},
   "source": [
    "## 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0cc4eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score,\n",
    "    average_precision_score\n",
    ")\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c333739",
   "metadata": {},
   "source": [
    "## 2. Load Clean Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42c9bde1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows: (13812, 10)\n"
     ]
    }
   ],
   "source": [
    "PATH = r\"C:/Users/saram/Desktop/Erdos_Institute/project-2025/\"\n",
    "DATA = \"bills_clean_phase1.csv\"\n",
    "\n",
    "bills = pd.read_csv(PATH + DATA)\n",
    "print(\"Total rows:\", bills.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c57f390",
   "metadata": {},
   "source": [
    "## 3. Train / Validation / Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a32d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mask = bills[\"congress\"].isin([113,114])\n",
    "val_mask   = bills[\"congress\"].isin([115,116])\n",
    "test_mask  = bills[\"congress\"] >= 117\n",
    "\n",
    "train = bills[train_mask]\n",
    "val   = bills[val_mask]\n",
    "test  = bills[test_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "43a0a109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN\n",
      "Rows: 1083\n",
      "Positives: 19\n",
      "VAL\n",
      "Rows: 5433\n",
      "Positives: 13\n",
      "TEST\n",
      "Rows: 7296\n",
      "Positives: 13\n"
     ]
    }
   ],
   "source": [
    "# Check the distribution\n",
    "def summarize(mask, name):\n",
    "    s = bills.loc[mask, \"label\"]\n",
    "    print(name)\n",
    "    print(\"Rows:\", len(s))\n",
    "    print(\"Positives:\", s.sum())\n",
    "\n",
    "summarize(train_mask, \"TRAIN\")\n",
    "summarize(val_mask, \"VAL\")\n",
    "summarize(test_mask, \"TEST\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c81c909",
   "metadata": {},
   "source": [
    "## 4. Targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b0eeaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train[\"label\"].values\n",
    "y_val   = val[\"label\"].values\n",
    "y_test  = test[\"label\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589ef085",
   "metadata": {},
   "source": [
    "# SECTION 5: TF-IDF BASELINES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d1c7c2",
   "metadata": {},
   "source": [
    "## 5. TF-IDF Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "73ff9605",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(\n",
    "    ngram_range=(1,2),\n",
    "    min_df=5,\n",
    "    max_df=0.9,\n",
    "    max_features=150_000,\n",
    "    token_pattern=r\"\\b[a-zA-Z]{3,}\\b\"\n",
    ")\n",
    "\n",
    "X_train = tfidf.fit_transform(train[\"clean_text\"])\n",
    "X_val   = tfidf.transform(val[\"clean_text\"])\n",
    "X_test  = tfidf.transform(test[\"clean_text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20deb13e",
   "metadata": {},
   "source": [
    "# SECTION 6: LINEAR MODELS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5b8d34",
   "metadata": {},
   "source": [
    "## 6. Logistic Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "79d6004e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(\n",
    "    max_iter=2500,\n",
    "    n_jobs=-1,\n",
    "    class_weight=\"balanced\"\n",
    ")\n",
    "\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "p_test_lr = lr.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ea09eb43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFIDF + Logistic\n",
      "ROC-AUC: 0.9707643722472776\n",
      "PR-AUC:  0.5279654808619086\n"
     ]
    }
   ],
   "source": [
    "# Evaluate (ranking metrics only)\n",
    "print(\"TFIDF + Logistic\")\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, p_test_lr))\n",
    "print(\"PR-AUC: \", average_precision_score(y_test, p_test_lr))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879163e8",
   "metadata": {},
   "source": [
    "## 7. SVM (Calibrated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1c1ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = LinearSVC(class_weight=\"balanced\")\n",
    "\n",
    "svm_cal = CalibratedClassifierCV(svm, method=\"sigmoid\", cv=5)\n",
    "\n",
    "svm_cal.fit(X_train, y_train)\n",
    "\n",
    "p_test_svm = svm_cal.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbda0c71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFIDF + SVM\n",
      "ROC-AUC: 0.9744082637121221\n",
      "PR-AUC:  0.6330011259115903\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "print(\"TFIDF + SVM\")\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, p_test_svm))\n",
    "print(\"PR-AUC: \", average_precision_score(y_test, p_test_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0608f523",
   "metadata": {},
   "source": [
    "# SECTION 7: TRANSFORMER EMBEDDINGS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5251e6df",
   "metadata": {},
   "source": [
    "## 8. Load MPNet & Encode All Bills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a4f3ba69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b60ccec4930f4e579b686a8e18306a36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/864 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = SentenceTransformer(\"all-mpnet-base-v2\")\n",
    "\n",
    "embeddings = model.encode(\n",
    "    bills[\"clean_text\"].astype(str).tolist(),\n",
    "    batch_size=16,\n",
    "    show_progress_bar=True\n",
    ")\n",
    "\n",
    "E = np.array(embeddings)\n",
    "\n",
    "X_train_e = E[train_mask.values]\n",
    "X_val_e   = E[val_mask.values]\n",
    "X_test_e  = E[test_mask.values]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79738b0",
   "metadata": {},
   "source": [
    "## 9. XGBoost on MPNet embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6d4cac06",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_pos = np.sum(y_train==0) / np.sum(y_train==1)\n",
    "\n",
    "xgb = XGBClassifier(\n",
    "    objective=\"binary:logistic\",\n",
    "    n_estimators=400,\n",
    "    learning_rate=0.02,\n",
    "    max_depth=4,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    scale_pos_weight=scale_pos,\n",
    "    eval_metric=\"logloss\",\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "xgb.fit(X_train_e, y_train)\n",
    "\n",
    "p_test_xgb = xgb.predict_proba(X_test_e)[:,1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "86c571ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPNet + XGB\n",
      "ROC-AUC: 0.9890049535799913\n",
      "PR-AUC:  0.6570914589302368\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "print(\"MPNet + XGB\")\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, p_test_xgb))\n",
    "print(\"PR-AUC: \", average_precision_score(y_test, p_test_xgb))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d7e1e5",
   "metadata": {},
   "source": [
    "# SECTION 8: MODEL LEADERBOARD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ec4a1972",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MODEL</th>\n",
       "      <th>ROC_AUC</th>\n",
       "      <th>PR_AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MPNet_XGB</td>\n",
       "      <td>0.989005</td>\n",
       "      <td>0.657091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TFIDF_SVM</td>\n",
       "      <td>0.974408</td>\n",
       "      <td>0.633001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TFIDF_LogReg</td>\n",
       "      <td>0.970764</td>\n",
       "      <td>0.527965</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          MODEL   ROC_AUC    PR_AUC\n",
       "2     MPNet_XGB  0.989005  0.657091\n",
       "1     TFIDF_SVM  0.974408  0.633001\n",
       "0  TFIDF_LogReg  0.970764  0.527965"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "results.append({\n",
    "    \"MODEL\":\"TFIDF_LogReg\",\n",
    "    \"ROC_AUC\": roc_auc_score(y_test, p_test_lr),\n",
    "    \"PR_AUC\":  average_precision_score(y_test, p_test_lr)\n",
    "})\n",
    "\n",
    "results.append({\n",
    "    \"MODEL\":\"TFIDF_SVM\",\n",
    "    \"ROC_AUC\": roc_auc_score(y_test, p_test_svm),\n",
    "    \"PR_AUC\":  average_precision_score(y_test, p_test_svm)\n",
    "})\n",
    "\n",
    "results.append({\n",
    "    \"MODEL\":\"MPNet_XGB\",\n",
    "    \"ROC_AUC\": roc_auc_score(y_test, p_test_xgb),\n",
    "    \"PR_AUC\":  average_precision_score(y_test, p_test_xgb)\n",
    "})\n",
    "\n",
    "leaderboard = pd.DataFrame(results)\n",
    "leaderboard.sort_values(\"PR_AUC\", ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e1921b08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'MODEL': 'TFIDF_LogReg',\n",
       "  'ROC_AUC': np.float64(0.9707643722472776),\n",
       "  'PR_AUC': np.float64(0.5279654808619086)},\n",
       " {'MODEL': 'TFIDF_SVM',\n",
       "  'ROC_AUC': np.float64(0.9744082637121221),\n",
       "  'PR_AUC': np.float64(0.6330011259115903)},\n",
       " {'MODEL': 'MPNet_XGB',\n",
       "  'ROC_AUC': np.float64(0.9890049535799913),\n",
       "  'PR_AUC': np.float64(0.6570914589302368)}]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf40e0b6",
   "metadata": {},
   "source": [
    "# SECTION 9: PROBABILITY SANITY CHECK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1ca461a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True pass rate: 0.001781798245614035\n",
      "TFIDF_LR mean predicted prob: 0.12028842375212986\n",
      "TFIDF_SVM mean predicted prob: 0.013985945471744575\n",
      "MPNet_XGB mean predicted prob: 0.005888514\n"
     ]
    }
   ],
   "source": [
    "# Ensure no leakage or overconfidence\n",
    "base_rate = y_test.mean()\n",
    "print(\"True pass rate:\", base_rate)\n",
    "\n",
    "for name, scores in [\n",
    "    (\"TFIDF_LR\",p_test_lr),\n",
    "    (\"TFIDF_SVM\",p_test_svm),\n",
    "    (\"MPNet_XGB\",p_test_xgb)\n",
    "]:\n",
    "    print(name, \"mean predicted prob:\", scores.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1289813e",
   "metadata": {},
   "source": [
    "**Interpretation**\n",
    "\n",
    "PR-AUC:\n",
    "\n",
    "* Base rate = 0.0018 (~0.18%) (`base_rate = y_test.mean()`, basically # passes / # number of bills in the test set)\n",
    "\n",
    "* Random PR-AUC ≈ base rate = 0.0018\n",
    "\n",
    "This means:\n",
    "\n",
    "* LogReg: 0.53 → ~300× better than random\n",
    "\n",
    "* SVM: 0.63 → ~350× better than random\n",
    "\n",
    "* MPNet+XGB: 0.66 → ~370× better than random\n",
    "\n",
    "In highly imbalanced data, a PR-AUC above 0.50 is already excellent.\n",
    "\n",
    "Thus:\n",
    "\n",
    "* Our models can consistently rank passing bills near the top of the list.\n",
    "\n",
    "* However, they can't perfectly say “yes/no” reliably yet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33512c66",
   "metadata": {},
   "source": [
    "**ROC-AUC high**\n",
    "\n",
    "ROC-AUC compares: Probability the model ranks a true positive higher than a random negative.\n",
    "\n",
    "ROC-AUC ≈ 0.99 means: In ~99% of positive–negative bill pairs, the positive bill has a higher score. That suggests strong ranking ability.\n",
    "\n",
    "However: ROC-AUC is optimistically inflated under heavy imbalance. It says nothing about how many false alarms you make when acting on predictions.\n",
    "\n",
    "ROC is good for sanity, but PR-AUC is good for real usefulness."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73223b20",
   "metadata": {},
   "source": [
    "**PR-AUC: Why 0.657 is huge here**\n",
    "\n",
    "Our dataset:\n",
    "\n",
    "* Positives: 13\n",
    "* Negatives: 7283\n",
    "\n",
    "Random guessing would give: PR-AUC ≈ 13 / 7296 ≈ 0.0018\n",
    "\n",
    "The MPNet: PR-AUC ≈ 0.657\n",
    "\n",
    "This is an enormous lift.\n",
    "\n",
    "What can it mean: The model puts most real successes near the top of its ranking, so checking the highest-scored bills lets you find winners quickly instead of hunting randomly.\n",
    "\n",
    "\"The model does not “predict yes or no.”\n",
    "It ranks bills from “most likely to pass” → “least likely to pass.”\n",
    "\n",
    "Because your PR-AUC is high (≈0.66) in a dataset where passes are extremely rare, it means:\n",
    "\n",
    "1. “Most true passing bills are near the top of the ranking”\n",
    "\n",
    "When you sort bills by model score:\n",
    "\n",
    "Top of list  →  highest chance to pass\n",
    "Bottom       →  lowest chance to pass\n",
    "\n",
    "The real winners tend to appear near the top, not scattered randomly.\n",
    "\n",
    "2. “Screening the top-N works”\n",
    "\n",
    "If you took only the top results from the ranking, for example:\n",
    "\n",
    "Top 50 bills\n",
    "or\n",
    "Top 100 bills\n",
    "\n",
    "you would capture many of the actual passing bills, instead of having to sift through thousands of failures.\"\n",
    "\n",
    "The model is good at triage:\n",
    "\n",
    "* It can point you to the few bills worth paying attention to.\n",
    "\n",
    "* It cannot confidently say “this bill will pass.”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173a3fee",
   "metadata": {},
   "source": [
    "**Interpretation of “mean predicted probability”**\n",
    "True pass rate: 0.00178\n",
    "\n",
    "TFIDF_LR mean predicted prob: 0.1203\n",
    "TFIDF_SVM mean predicted prob: 0.0140\n",
    "MPNet_XGB mean predicted prob: 0.0059\n",
    "\n",
    "What should it be?\n",
    "\n",
    "Good calibration: mean predicted prob ≈ true rate\n",
    "\n",
    "Our models mean predicted prob seems inflated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0729b0e5",
   "metadata": {},
   "source": [
    "**TF-IDF + LogReg**\n",
    "\n",
    "* Bad probability calibration\n",
    "\n",
    "* The model is overconfident.\n",
    "\n",
    "* It assigns probabilities far too high for a 0.18% event.\n",
    "\n",
    "**SVM + calibration**\n",
    "\n",
    "* Better but still inflated\n",
    "\n",
    "**MPNet + XGB**\n",
    "\n",
    "* BEST calibrated model\n",
    "\n",
    "3.3× inflation is actually good under our constraints.\n",
    "\n",
    "This is a strong sign:\n",
    "\n",
    "* Best ranking, least miscalibration, most stable learner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59936ee",
   "metadata": {},
   "source": [
    "**What these models are good for**\n",
    "\n",
    "* Rank bills by passage likelihood extremely well.\n",
    "\n",
    "* Identify top candidates worth human focus.\n",
    "\n",
    "* Serve as a decision-support filter.\n",
    "\n",
    "What they cannot do:\n",
    "\n",
    "* Serve as a fully automated yes/no classifier.\n",
    "\n",
    "* Provide literal probabilities like “this bill has 60% chance.”\n",
    "\n",
    "* Be used for naive threshold decisions like p > 0.5.\n",
    "\n",
    "\n",
    "**Best Model:** MPNet + XGBoost\n",
    "\n",
    "Reasons:\n",
    "\n",
    "* Highest PR-AUC\n",
    "\n",
    "* Highest ROC-AUC\n",
    "\n",
    "* Best probability calibration\n",
    "\n",
    "* Transformer signal beats bag-of-words"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erdos_fall_2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
